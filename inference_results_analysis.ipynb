{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55384a70",
   "metadata": {},
   "source": [
    "# Flow Field Reconstruction - Inference Results Analysis\n",
    "\n",
    "This notebook analyzes the reconstructed flow fields from various models (FLRNet, MLP, POD) using inference results stored in the checkpoints directory. The analysis includes comprehensive visualization with enhanced color maps for better visual interpretation.\n",
    "\n",
    "## Overview\n",
    "- Load pre-computed inference results from different models\n",
    "- Compare reconstruction accuracy across various conditions\n",
    "- Generate publication-quality plots with optimized color schemes\n",
    "- Analyze effects of sensor count, layout, noise, and Reynolds number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a21c7e",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c287d230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Enhanced color schemes initialized.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up improved plotting parameters similar to PDF style\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans', 'Liberation Sans']\n",
    "plt.rcParams['axes.linewidth'] = 0.8\n",
    "plt.rcParams['lines.linewidth'] = 1.0\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['xtick.direction'] = 'out'\n",
    "plt.rcParams['ytick.direction'] = 'out'\n",
    "plt.rcParams['xtick.major.size'] = 3\n",
    "plt.rcParams['ytick.major.size'] = 3\n",
    "\n",
    "# Define enhanced color palettes\n",
    "COLORS = {\n",
    "    'flrnet': '#2E86AB',      # Ocean blue\n",
    "    'flrnet_fourier': '#A23B72', # Deep magenta  \n",
    "    'mlp': '#F18F01',         # Golden orange\n",
    "    'pod': '#C73E1D',         # Crimson red\n",
    "    'ground_truth': '#3A5F0B' # Forest green\n",
    "}\n",
    "\n",
    "# Enhanced colormap for field visualization\n",
    "def create_enhanced_colormap():\n",
    "    \"\"\"Create enhanced colormap similar to PDF file\"\"\"\n",
    "    # Use a more scientific colormap similar to the PDF\n",
    "    colors = ['#000428', '#004e92', '#009ffd', '#00d2ff', '#ffffff', '#ffff00', '#ff6600', '#ff0000', '#8b0000']\n",
    "    n_bins = 256\n",
    "    cmap = LinearSegmentedColormap.from_list('enhanced_field', colors, N=n_bins)\n",
    "    return cmap\n",
    "\n",
    "# Enhanced diverging colormap for error visualization  \n",
    "def create_error_colormap():\n",
    "    \"\"\"Create enhanced diverging colormap for error visualization\"\"\"\n",
    "    # Blue-white-red diverging colormap\n",
    "    colors = ['#2166ac', '#4393c3', '#92c5de', '#d1e5f0', '#f7f7f7', '#fddbc7', '#f4a582', '#d6604d', '#b2182b']\n",
    "    n_bins = 256\n",
    "    cmap = LinearSegmentedColormap.from_list('enhanced_error', colors, N=n_bins)\n",
    "    return cmap\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(\"Enhanced color schemes initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7253b3",
   "metadata": {},
   "source": [
    "## Load Reconstructed Field Data\n",
    "\n",
    "Load pre-computed inference results from the checkpoints directory. The results include reconstructed fields from different models and configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02de3702",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "inference_results_path = r\"E:\\Research\\Physics-informed-machine-learning\\flow_field_recon_parc\\checkpoints\\inference_results\"\n",
    "data_path = r\"E:\\Research\\Data\\NavierStokes\\test\"\n",
    "\n",
    "# Check if inference results directory exists\n",
    "if not os.path.exists(inference_results_path):\n",
    "    print(f\"Warning: Inference results directory not found at {inference_results_path}\")\n",
    "    print(\"Available checkpoints:\")\n",
    "    checkpoints_path = r\"E:\\Research\\Physics-informed-machine-learning\\flow_field_recon_parc\\checkpoints\"\n",
    "    if os.path.exists(checkpoints_path):\n",
    "        for item in os.listdir(checkpoints_path):\n",
    "            print(f\"  - {item}\")\n",
    "\n",
    "def load_inference_results():\n",
    "    \"\"\"Load all inference results from the checkpoints directory\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Look for .npz files in the inference_results directory and subdirectories\n",
    "    search_patterns = [\n",
    "        os.path.join(inference_results_path, \"*.npz\"),\n",
    "        os.path.join(inference_results_path, \"**\", \"*.npz\"),\n",
    "        # Also check main checkpoints directory\n",
    "        r\"E:\\Research\\Physics-informed-machine-learning\\flow_field_recon_parc\\checkpoints\\*.npz\"\n",
    "    ]\n",
    "    \n",
    "    found_files = []\n",
    "    for pattern in search_patterns:\n",
    "        found_files.extend(glob.glob(pattern, recursive=True))\n",
    "    \n",
    "    print(f\"Found {len(found_files)} .npz files:\")\n",
    "    for file_path in found_files:\n",
    "        print(f\"  - {os.path.basename(file_path)}\")\n",
    "        \n",
    "        try:\n",
    "            # Load the file\n",
    "            data = np.load(file_path)\n",
    "            file_name = os.path.basename(file_path).replace('.npz', '')\n",
    "            \n",
    "            # Extract key information from filename based on new convention\n",
    "            if file_name.startswith('inference_'):\n",
    "                # FLRNet models: inference_{layout}_{no_of_sensor}_{config}\n",
    "                parts = file_name.split('_')\n",
    "                if len(parts) >= 4:\n",
    "                    config = '_'.join(parts[3:])  # Handle multi-part configs like 'no_fourier_no_percep'\n",
    "                    if config == 'standard':\n",
    "                        model_type = 'flrnet_fourier_percep'  # With fourier and perceptual\n",
    "                    elif config == 'fourier':\n",
    "                        model_type = 'flrnet_fourier'  # Fourier only\n",
    "                    elif config == 'no_fourier':\n",
    "                        model_type = 'flrnet_percep'  # Perceptual only\n",
    "                    elif config == 'no_fourier_no_percep':\n",
    "                        model_type = 'flrnet_standard'  # Vanilla VAE\n",
    "                    else:\n",
    "                        model_type = 'flrnet_unknown'\n",
    "                else:\n",
    "                    model_type = 'flrnet_unknown'\n",
    "            elif file_name.startswith('mlp_'):\n",
    "                model_type = 'mlp'\n",
    "            elif file_name.startswith('pod_'):\n",
    "                model_type = 'pod'\n",
    "            else:\n",
    "                model_type = 'unknown'\n",
    "            \n",
    "            # Store data with metadata\n",
    "            results[file_name] = {\n",
    "                'data': data,\n",
    "                'model_type': model_type,\n",
    "                'file_path': file_path\n",
    "            }\n",
    "            \n",
    "            print(f\"    Loaded: {file_name} ({model_type}) - Keys: {list(data.keys())}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    Error loading {file_path}: {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Load all inference results\n",
    "inference_data = load_inference_results()\n",
    "\n",
    "print(f\"\\nSuccessfully loaded {len(inference_data)} inference result files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf96168",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Normalization\n",
    "\n",
    "Organize and preprocess the loaded data for consistent analysis across different models and configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a247ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def categorize_flrnet_model(filename):\n",
    "    \"\"\"Categorize FLRNet models based on filename config pattern\"\"\"\n",
    "    # Parse filename: inference_{layout}_{no_of_sensor}_{config}\n",
    "    parts = filename.split('_')\n",
    "    if len(parts) >= 4:\n",
    "        config = '_'.join(parts[3:])  # Handle multi-part configs\n",
    "        \n",
    "        if config == 'standard':\n",
    "            return 'flrnet_fourier_percep'  # With fourier and perceptual\n",
    "        elif config == 'fourier':\n",
    "            return 'flrnet_fourier'  # Fourier only\n",
    "        elif config == 'no_fourier':\n",
    "            return 'flrnet_percep'  # Perceptual only\n",
    "        elif config == 'no_fourier_no_percep':\n",
    "            return 'flrnet_standard'  # Vanilla VAE\n",
    "    \n",
    "    return 'flrnet_unknown'  # Fallback\n",
    "\n",
    "def load_and_organize_data():\n",
    "    \"\"\"Load all .npz files and organize them by model type\"\"\"\n",
    "    \n",
    "    # Search patterns for finding .npz files\n",
    "    search_patterns = [\n",
    "        os.path.join(inference_results_path, \"*.npz\"),\n",
    "        os.path.join(inference_results_path, \"**\", \"*.npz\"),\n",
    "    ]\n",
    "    \n",
    "    # Find all .npz files\n",
    "    all_files = []\n",
    "    for pattern in search_patterns:\n",
    "        all_files.extend(glob.glob(pattern, recursive=True))\n",
    "    \n",
    "    # Initialize organized data structure\n",
    "    organized_data = {\n",
    "        'flrnet_fourier_percep': {},  # standard config\n",
    "        'flrnet_fourier': {},         # fourier config\n",
    "        'flrnet_percep': {},          # no_fourier config\n",
    "        'flrnet_standard': {},        # no_fourier_no_percep config (vanilla VAE)\n",
    "        'mlp': {},\n",
    "        'pod': {},\n",
    "        'ground_truth': {}\n",
    "    }\n",
    "    \n",
    "    # Ground truth data\n",
    "    gt_data = None\n",
    "    gt_info = {}\n",
    "    \n",
    "    # Process each file\n",
    "    for file_path in all_files:\n",
    "        try:\n",
    "            filename = os.path.basename(file_path).replace('.npz', '')\n",
    "            data = np.load(file_path)\n",
    "            \n",
    "            # Determine model category based on filename pattern\n",
    "            if filename.startswith('inference_'):\n",
    "                category = categorize_flrnet_model(filename)\n",
    "            elif filename.startswith('mlp_'):\n",
    "                category = 'mlp'\n",
    "            elif filename.startswith('pod_'):\n",
    "                category = 'pod'\n",
    "            else:\n",
    "                continue  # Skip unknown files\n",
    "            \n",
    "            # Extract model features from filename\n",
    "            info = extract_model_info(filename)\n",
    "            \n",
    "            # Store in organized structure\n",
    "            organized_data[category][filename] = {\n",
    "                'data': data,\n",
    "                'info': info,\n",
    "                'file_path': file_path\n",
    "            }\n",
    "            \n",
    "            # Extract ground truth from first available file\n",
    "            if gt_data is None and 'targets' in data:\n",
    "                gt_data = data['targets']\n",
    "                gt_info = info.copy()\n",
    "                gt_info['source'] = filename\n",
    "                organized_data['ground_truth']['targets'] = {\n",
    "                    'data': {'targets': gt_data},\n",
    "                    'info': gt_info,\n",
    "                    'file_path': file_path\n",
    "                }\n",
    "                print(f\"✓ Ground truth extracted from {filename}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error loading {file_path}: {e}\")\n",
    "    \n",
    "    return organized_data, gt_data, gt_info\n",
    "\n",
    "def extract_model_info(filename):\n",
    "    \"\"\"Extract metadata from filename based on naming convention\"\"\"\n",
    "    info = {\n",
    "        'filename': filename,\n",
    "        'variant': 'unknown',\n",
    "        'num_sensors': 0,\n",
    "        'sensor_layout': 'unknown',\n",
    "        'has_fourier': False,\n",
    "        'has_perceptual': False,\n",
    "        'config': 'unknown'\n",
    "    }\n",
    "    \n",
    "    parts = filename.split('_')\n",
    "    \n",
    "    if filename.startswith('inference_'):\n",
    "        # Pattern: inference_{layout}_{no_of_sensor}_{config}\n",
    "        if len(parts) >= 4:\n",
    "            layout = parts[1]\n",
    "            num_sensors = int(parts[2]) if parts[2].isdigit() else 0\n",
    "            config = '_'.join(parts[3:])\n",
    "            \n",
    "            info['sensor_layout'] = layout\n",
    "            info['num_sensors'] = num_sensors\n",
    "            info['config'] = config\n",
    "            \n",
    "            # Determine features based on config\n",
    "            if config == 'standard':\n",
    "                info['variant'] = 'fourier_percep'\n",
    "                info['has_fourier'] = True\n",
    "                info['has_perceptual'] = True\n",
    "            elif config == 'fourier':\n",
    "                info['variant'] = 'fourier'\n",
    "                info['has_fourier'] = True\n",
    "                info['has_perceptual'] = False\n",
    "            elif config == 'no_fourier':\n",
    "                info['variant'] = 'percep'\n",
    "                info['has_fourier'] = False\n",
    "                info['has_perceptual'] = True\n",
    "            elif config == 'no_fourier_no_percep':\n",
    "                info['variant'] = 'standard'\n",
    "                info['has_fourier'] = False\n",
    "                info['has_perceptual'] = False\n",
    "                \n",
    "    elif filename.startswith(('mlp_', 'pod_')):\n",
    "        # Pattern: {model}_{layout}_{no_of_sensor}_standard\n",
    "        if len(parts) >= 4:\n",
    "            layout = parts[1]\n",
    "            num_sensors = int(parts[2]) if parts[2].isdigit() else 0\n",
    "            config = parts[3]\n",
    "            \n",
    "            info['sensor_layout'] = layout\n",
    "            info['num_sensors'] = num_sensors\n",
    "            info['config'] = config\n",
    "            info['variant'] = filename.split('_')[0]  # 'mlp' or 'pod'\n",
    "    \n",
    "    return info\n",
    "\n",
    "# Load and organize all data\n",
    "organized_data, gt_data, gt_info = load_and_organize_data()\n",
    "\n",
    "# Print detailed summary\n",
    "print(\"Detailed Data Organization Summary:\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Count files in each category\n",
    "category_counts = {category: len(files) for category, files in organized_data.items()}\n",
    "\n",
    "print(\"FLRNet Variants:\")\n",
    "print(f\"  • FLRNet (Fourier + Perceptual) [standard]: {category_counts['flrnet_fourier_percep']} files\")\n",
    "print(f\"  • FLRNet (Fourier only) [fourier]: {category_counts['flrnet_fourier']} files\")\n",
    "print(f\"  • FLRNet (Perceptual only) [no_fourier]: {category_counts['flrnet_percep']} files\")\n",
    "print(f\"  • FLRNet (Vanilla VAE) [no_fourier_no_percep]: {category_counts['flrnet_standard']} files\")\n",
    "print()\n",
    "print(\"Other Models:\")\n",
    "print(f\"  • MLP: {category_counts['mlp']} files\")\n",
    "print(f\"  • POD: {category_counts['pod']} files\")\n",
    "print()\n",
    "print(\"Ground Truth:\")\n",
    "print(f\"  • Ground Truth: {category_counts['ground_truth']} extracted\")\n",
    "print()\n",
    "\n",
    "# Show detailed breakdown for each category\n",
    "for category, files in organized_data.items():\n",
    "    if files and category != 'ground_truth':\n",
    "        print(f\"{category.upper().replace('_', ' ')}:\")\n",
    "        for filename, model_data in files.items():\n",
    "            info = model_data['info']\n",
    "            data = model_data['data']\n",
    "            pred_shape = data['predictions'].shape if 'predictions' in data else \"N/A\"\n",
    "            targets_shape = data['targets'].shape if 'targets' in data else \"N/A\"\n",
    "            \n",
    "            print(f\"  - {filename}\")\n",
    "            print(f\"    Config: {info['config']}, Variant: {info['variant']}\")\n",
    "            print(f\"    Sensors: {info['num_sensors']}, Layout: {info['sensor_layout']}\")\n",
    "            print(f\"    Fourier: {info['has_fourier']}, Perceptual: {info['has_perceptual']}\")\n",
    "            print(f\"    Predictions: {pred_shape}, Targets: {targets_shape}\")\n",
    "        print()\n",
    "\n",
    "if gt_data is not None:\n",
    "    print(\"GROUND TRUTH:\")\n",
    "    print(f\"  - Source: {gt_info['source']}\")\n",
    "    print(f\"  - Shape: {gt_data.shape}\")\n",
    "else:\n",
    "    print(\"⚠ WARNING: No ground truth data found!\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(f\"TOTAL FILES ORGANIZED: {sum(category_counts.values()) - category_counts['ground_truth']}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d9cfb9",
   "metadata": {},
   "source": [
    "## Load Ground Truth Data for Comparison\n",
    "\n",
    "Load the corresponding ground truth flow field data for error calculation and comparative analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43a23fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ground_truth_from_inference_data():\n",
    "    \"\"\"Load ground truth data from embedded 'targets' in inference files\"\"\"\n",
    "    \n",
    "    print(\"Loading ground truth data from inference files:\")\n",
    "    \n",
    "    # Get ground truth from the first available inference file (all should have the same targets)\n",
    "    gt_data = None\n",
    "    sample_file = None\n",
    "    \n",
    "    for file_name, file_info in inference_data.items():\n",
    "        data = file_info['data']\n",
    "        if 'targets' in data:\n",
    "            gt_data = data['targets']\n",
    "            sample_file = file_name\n",
    "            break\n",
    "    \n",
    "    if gt_data is not None:\n",
    "        print(f\"  ✓ Ground truth loaded from: {sample_file}\")\n",
    "        print(f\"  ✓ Ground truth shape: {gt_data.shape}\")\n",
    "        \n",
    "        # Reshape data to have time as first dimension: (time, height, width, channels)\n",
    "        # Original shape: (batch, height, width, time) -> (time, height, width, batch)\n",
    "        if len(gt_data.shape) == 4:\n",
    "            gt_data = np.transpose(gt_data, (3, 1, 2, 0))  # Move time from last to first\n",
    "            print(f\"  ✓ Reshaped to: {gt_data.shape} (time, height, width, channels)\")\n",
    "        \n",
    "        # Calculate normalization parameters from the ground truth data itself\n",
    "        min_val = np.min(gt_data)\n",
    "        max_val = np.max(gt_data)\n",
    "        \n",
    "        print(f\"  ✓ Ground truth range: [{min_val:.6f}, {max_val:.6f}]\")\n",
    "        \n",
    "        return gt_data, min_val, max_val\n",
    "    else:\n",
    "        print(\"  ✗ No ground truth data found in inference files!\")\n",
    "        return None, None, None\n",
    "\n",
    "# Load ground truth from embedded data\n",
    "gt_data, min_val, max_val = load_ground_truth_from_inference_data()\n",
    "\n",
    "if gt_data is not None:\n",
    "    # The data is already in the correct format, no additional normalization needed\n",
    "    print(f\"Ground truth data successfully loaded: {gt_data.shape}\")\n",
    "    print(f\"Value range: [{np.min(gt_data):.6f}, {np.max(gt_data):.6f}]\")\n",
    "else:\n",
    "    print(\"Warning: No ground truth data available for analysis\")\n",
    "    min_val, max_val = 0.0, 1.0  # Default values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2bcaa1",
   "metadata": {},
   "source": [
    "## Calculate Error Metrics\n",
    "\n",
    "Compute comprehensive error metrics between ground truth and reconstructed fields for quantitative analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cc875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error_metrics(gt_data, pred_data):\n",
    "    \"\"\"Calculate comprehensive error metrics\"\"\"\n",
    "    # Mean Absolute Error\n",
    "    mae = np.mean(np.abs(gt_data - pred_data))\n",
    "    \n",
    "    # Root Mean Square Error\n",
    "    rmse = np.sqrt(np.mean((gt_data - pred_data)**2))\n",
    "    \n",
    "    # Mean Absolute Percentage Error\n",
    "    mape = np.mean(np.abs((gt_data - pred_data) / (gt_data + 1e-8))) * 100\n",
    "    \n",
    "    # Normalized MAE\n",
    "    mae_normalized = mae / (np.max(gt_data) - np.min(gt_data))\n",
    "    \n",
    "    return {\n",
    "        'mae': mae,\n",
    "        'rmse': rmse, \n",
    "        'mape': mape,\n",
    "        'mae_normalized': mae_normalized\n",
    "    }\n",
    "def process_inference_results_for_analysis():\n",
    "    \"\"\"Process inference results and calculate error metrics using embedded targets\"\"\"\n",
    "    model_results = {\n",
    "        'flrnet_fourier_percep': [],  # standard config\n",
    "        'flrnet_fourier': [],         # fourier config\n",
    "        'flrnet_percep': [],          # no_fourier config\n",
    "        'flrnet_standard': [],        # no_fourier_no_percep config\n",
    "        'mlp': [],\n",
    "        'pod': []\n",
    "    }\n",
    "    \n",
    "    error_metrics = {\n",
    "        'flrnet_fourier_percep': [],\n",
    "        'flrnet_fourier': [],\n",
    "        'flrnet_percep': [],\n",
    "        'flrnet_standard': [],\n",
    "        'mlp': [],\n",
    "        'pod': []\n",
    "    }\n",
    "    \n",
    "    configs = {\n",
    "        'flrnet_fourier_percep': [],\n",
    "        'flrnet_fourier': [],\n",
    "        'flrnet_percep': [],\n",
    "        'flrnet_standard': [],\n",
    "        'mlp': [],\n",
    "        'pod': []\n",
    "    }\n",
    "    \n",
    "    if gt_data is None:\n",
    "        print(\"Warning: No ground truth data available for error calculation\")\n",
    "        return model_results, error_metrics, configs\n",
    "    \n",
    "    print(\"Processing inference results for analysis:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for model_type in model_results.keys():\n",
    "        if model_type in organized_data and organized_data[model_type]:\n",
    "            print(f\"\\n{model_type.upper()}:\")\n",
    "            \n",
    "            for file_name, file_info in organized_data[model_type].items():\n",
    "                data = file_info['data']\n",
    "                info = file_info['info']\n",
    "                \n",
    "                # Use predictions and targets from the same file\n",
    "                if 'predictions' in data and 'targets' in data:\n",
    "                    predictions = data['predictions']\n",
    "                    targets = data['targets']\n",
    "                    \n",
    "                    # Reshape predictions and targets to have time as first dimension if needed\n",
    "                    if len(predictions.shape) == 4 and predictions.shape[3] > predictions.shape[0]:\n",
    "                        predictions = np.transpose(predictions, (3, 1, 2, 0))\n",
    "                        targets = np.transpose(targets, (3, 1, 2, 0))\n",
    "                    \n",
    "                    # Ensure consistent shapes\n",
    "                    if predictions.shape != targets.shape:\n",
    "                        print(f\"  Warning: Shape mismatch for {file_name}\")\n",
    "                        print(f\"    Predictions: {predictions.shape}\")\n",
    "                        print(f\"    Targets: {targets.shape}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Calculate error metrics using predictions and targets directly\n",
    "                    metrics = calculate_error_metrics(targets, predictions)\n",
    "                    \n",
    "                    # Store results\n",
    "                    model_results[model_type].append(predictions)\n",
    "                    error_metrics[model_type].append(metrics)\n",
    "                    configs[model_type].append(info)\n",
    "                    \n",
    "                    print(f\"  ✓ {file_name}\")\n",
    "                    print(f\"    Config: {info['config']}\")\n",
    "                    print(f\"    MAE: {metrics['mae']:.6f}\")\n",
    "                    print(f\"    RMSE: {metrics['rmse']:.6f}\")\n",
    "                    \n",
    "                else:\n",
    "                    print(f\"  ✗ {file_name}: Missing 'predictions' or 'targets' key\")\n",
    "                    print(f\"    Available keys: {list(data.keys())}\")\n",
    "        else:\n",
    "            print(f\"\\n{model_type.upper()}: No data found\")\n",
    "    \n",
    "    return model_results, error_metrics, configs\n",
    "\n",
    "# Process all inference results\n",
    "model_results, error_metrics, configs = process_inference_results_for_analysis()\n",
    "\n",
    "print(f\"\\nSummary of processed results:\")\n",
    "for model_type in model_results.keys():\n",
    "    count = len(model_results[model_type])\n",
    "    print(f\"  {model_type}: {count} files processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e02ffc",
   "metadata": {},
   "source": [
    "## Enhanced Plotting Functions\n",
    "\n",
    "Define improved plotting functions with enhanced color schemes and better visual presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d698bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_enhanced_comparison_plot(x_data, y_data_dict, title, xlabel, ylabel, \n",
    "                                   figsize=(10, 7), save_name=None):\n",
    "    \"\"\"Create enhanced comparison plot with improved styling\"\"\"\n",
    "    fig, ax1 = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Enhanced color scheme\n",
    "    colors = [COLORS['flrnet'], COLORS['flrnet_fourier'], COLORS['mlp'], COLORS['pod']]\n",
    "    markers = ['o', 's', '^', 'd']\n",
    "    linestyles = ['-', '--', '-.', ':']\n",
    "    \n",
    "    # Plot data\n",
    "    for i, (model_name, y_data) in enumerate(y_data_dict.items()):\n",
    "        if len(y_data) > 0:\n",
    "            ax1.plot(x_data[:len(y_data)], y_data, \n",
    "                    label=model_name.replace('_', ' ').title(), \n",
    "                    color=colors[i % len(colors)], \n",
    "                    linestyle=linestyles[i % len(linestyles)],\n",
    "                    linewidth=2.5, \n",
    "                    marker=markers[i % len(markers)],\n",
    "                    markersize=8,\n",
    "                    markerfacecolor='white',\n",
    "                    markeredgewidth=2)\n",
    "    \n",
    "    # Styling\n",
    "    ax1.set_title(title, fontsize=18, fontweight='bold', pad=20)\n",
    "    ax1.set_xlabel(xlabel, fontsize=14, fontweight='bold')\n",
    "    ax1.set_ylabel(ylabel, fontsize=14, fontweight='bold')\n",
    "    ax1.legend(loc='upper right', fontsize=12, frameon=True, fancybox=True, shadow=True)\n",
    "    ax1.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax1.tick_params(axis='both', which='major', labelsize=12)\n",
    "    \n",
    "    # Add secondary y-axis for percentage\n",
    "    ax2 = ax1.twinx()\n",
    "    for i, (model_name, y_data) in enumerate(y_data_dict.items()):\n",
    "        if len(y_data) > 0:\n",
    "            y_percentage = np.array(y_data) / max_val * 100\n",
    "            ax2.plot(x_data[:len(y_data)], y_percentage, \n",
    "                    color=colors[i % len(colors)], \n",
    "                    linestyle=linestyles[i % len(linestyles)],\n",
    "                    linewidth=2.5, \n",
    "                    marker=markers[i % len(markers)],\n",
    "                    markersize=8,\n",
    "                    markerfacecolor='white',\n",
    "                    markeredgewidth=2,\n",
    "                    alpha=0.7)\n",
    "    \n",
    "    ax2.set_ylabel('Mean Absolute Percentage Error (%)', fontsize=14, fontweight='bold')\n",
    "    ax2.tick_params(axis='y', labelcolor='black', labelsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_name:\n",
    "        plt.savefig(f\"{save_name}.png\", dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.savefig(f\"{save_name}.pdf\", dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2acd2b5",
   "metadata": {},
   "source": [
    "## Effect of Number of Sensors Analysis\n",
    "\n",
    "Analyze how reconstruction accuracy varies with the number of sensors (8, 16, 32) using enhanced visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da477edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Check organized data structure\n",
    "print(\"Debug: Organized data structure:\")\n",
    "print(\"=\" * 50)\n",
    "for model_type, model_data in organized_data.items():\n",
    "    print(f\"\\n{model_type}: {len(model_data) if model_data else 0} files\")\n",
    "    if model_data:\n",
    "        for file_name in list(model_data.keys())[:3]:  # Show first 3 files\n",
    "            print(f\"  - {file_name}\")\n",
    "\n",
    "print(\"\\nDebug: Original inference data:\")\n",
    "print(\"=\" * 50)\n",
    "for file_name in list(inference_data.keys())[:5]:  # Show first 5 files\n",
    "    file_info = inference_data[file_name]\n",
    "    print(f\"{file_name}:\")\n",
    "    print(f\"  Model type: {file_info['model_type']}\")\n",
    "    print(f\"  Data keys: {list(file_info['data'].keys())}\")\n",
    "\n",
    "# Now proceed with the analysis using the correct data structure\n",
    "print(\"\\n\\nAnalyzing sensor count effects:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Collect sensor count data from organized structure\n",
    "sensor_count_results = {}\n",
    "\n",
    "for model_type, model_data in organized_data.items():\n",
    "    if model_type == 'ground_truth' or not model_data:\n",
    "        continue\n",
    "        \n",
    "    for file_name, file_info in model_data.items():\n",
    "        info = file_info['info']  # This is the info dictionary\n",
    "        sensor_count = info['num_sensors']  # Use num_sensors instead of config['sensor_count']\n",
    "        layout = info['sensor_layout']  # Use sensor_layout instead of config['layout']\n",
    "        \n",
    "        if sensor_count:\n",
    "            if sensor_count not in sensor_count_results:\n",
    "                sensor_count_results[sensor_count] = {}\n",
    "            if model_type not in sensor_count_results[sensor_count]:\n",
    "                sensor_count_results[sensor_count][model_type] = {}\n",
    "            if layout not in sensor_count_results[sensor_count][model_type]:\n",
    "                sensor_count_results[sensor_count][model_type][layout] = []\n",
    "            \n",
    "            # Calculate basic metrics\n",
    "            predictions = file_info['data']['predictions']\n",
    "            targets = file_info['data']['targets']\n",
    "            \n",
    "            # Calculate MSE\n",
    "            mae = np.abs((predictions - targets))\n",
    "            \n",
    "            sensor_count_results[sensor_count][model_type][layout].append({\n",
    "                'file': file_name,\n",
    "                'mae': mae,\n",
    "                'predictions': predictions,\n",
    "                'targets': targets\n",
    "            })\n",
    "\n",
    "# Display sensor count analysis\n",
    "for sensor_count in sorted(sensor_count_results.keys()):\n",
    "    print(f\"\\nSensor count: {sensor_count}\")\n",
    "    for model_type, model_results in sensor_count_results[sensor_count].items():\n",
    "        for layout, layout_results in model_results.items():\n",
    "            avg_mae = np.mean([r['mae'] for r in layout_results])\n",
    "            print(f\"  {model_type} ({layout}): {len(layout_results)} files, Avg MSE: {avg_mae:.6f}\")\n",
    "\n",
    "print(f\"\\nTotal configurations found: {sum(len(model_data) for model_data in organized_data.values() if model_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6e30f1",
   "metadata": {},
   "source": [
    "## Effect of Sensor Layout Analysis\n",
    "\n",
    "Compare different sensor layouts (Random, Circular, Edge) and their impact on reconstruction quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30f54ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sensor count comparison plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare data for visualization\n",
    "sensor_counts = sorted(sensor_count_results.keys())\n",
    "model_types = ['flrnet', 'flrnet_fourier', 'mlp', 'pod']\n",
    "layouts = ['random', 'circular', 'edge']\n",
    "\n",
    "# Create comprehensive sensor count analysis plot\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Model Performance Analysis Across Different Configurations', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: MSE by Sensor Count (averaged across layouts)\n",
    "ax1 = axes[0, 0]\n",
    "for model_type in model_types:\n",
    "    sensor_maes = []\n",
    "    for sensor_count in sensor_counts:\n",
    "        if sensor_count in sensor_count_results and model_type in sensor_count_results[sensor_count]:\n",
    "            # Average across all layouts for this sensor count and model\n",
    "            all_maes = []\n",
    "            for layout in sensor_count_results[sensor_count][model_type]:\n",
    "                layout_maes = [r['mae'] for r in sensor_count_results[sensor_count][model_type][layout]]\n",
    "                all_maes.extend(layout_maes)\n",
    "            if all_maes:\n",
    "                sensor_maes.append(np.mean(all_maes))\n",
    "            else:\n",
    "                sensor_maes.append(np.nan)\n",
    "        else:\n",
    "            sensor_maes.append(np.nan)\n",
    "    \n",
    "    # Remove NaN values for plotting\n",
    "    valid_indices = ~np.isnan(sensor_maes)\n",
    "    if np.any(valid_indices):\n",
    "        ax1.plot(np.array(sensor_counts)[valid_indices], np.array(sensor_maes)[valid_indices], \n",
    "                'o-', linewidth=2, markersize=8, label=model_type.upper())\n",
    "\n",
    "ax1.set_xlabel('Number of Sensors', fontsize=12)\n",
    "ax1.set_ylabel('Mean Squared Error', fontsize=12)\n",
    "ax1.set_title('Model Performance vs Sensor Count', fontsize=14)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_yscale('log')\n",
    "\n",
    "# Plot 2: Layout comparison for 32 sensors\n",
    "ax2 = axes[0, 1]\n",
    "if 32 in sensor_count_results:\n",
    "    layouts_available = []\n",
    "    model_maes = {model: [] for model in model_types}\n",
    "    \n",
    "    for layout in layouts:\n",
    "        layout_found = False\n",
    "        for model_type in model_types:\n",
    "            if model_type in sensor_count_results[32] and layout in sensor_count_results[32][model_type]:\n",
    "                layout_maes = [r['mae'] for r in sensor_count_results[32][model_type][layout]]\n",
    "                model_maes[model_type].append(np.mean(layout_maes))\n",
    "                layout_found = True\n",
    "            else:\n",
    "                model_maes[model_type].append(np.nan)\n",
    "        if layout_found:\n",
    "            layouts_available.append(layout)\n",
    "    \n",
    "    x = np.arange(len(layouts_available))\n",
    "    width = 0.2\n",
    "    \n",
    "    for i, model_type in enumerate(model_types):\n",
    "        valid_maes = [model_maes[model_type][j] for j in range(len(layouts_available)) \n",
    "                     if not np.isnan(model_maes[model_type][j])]\n",
    "        valid_layouts = [layouts_available[j] for j in range(len(layouts_available)) \n",
    "                        if not np.isnan(model_maes[model_type][j])]\n",
    "        \n",
    "        if valid_maes:\n",
    "            ax2.bar(np.arange(len(valid_layouts)) + i*width, valid_maes, width, \n",
    "                   label=model_type.upper(), alpha=0.8)\n",
    "    \n",
    "    ax2.set_xlabel('Sensor Layout', fontsize=12)\n",
    "    ax2.set_ylabel('Mean Squared Error', fontsize=12)\n",
    "    ax2.set_title('Layout Comparison (32 Sensors)', fontsize=14)\n",
    "    ax2.set_xticks(x + width*1.5)\n",
    "    ax2.set_xticklabels(layouts_available)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Model variant comparison\n",
    "ax3 = axes[1, 0]\n",
    "model_variant_data = {}\n",
    "for sensor_count in sensor_count_results:\n",
    "    for model_type in sensor_count_results[sensor_count]:\n",
    "        for layout in sensor_count_results[sensor_count][model_type]:\n",
    "            for result in sensor_count_results[sensor_count][model_type][layout]:\n",
    "                key = f\"{model_type}_{layout}_{sensor_count}\"\n",
    "                if key not in model_variant_data:\n",
    "                    model_variant_data[key] = []\n",
    "                model_variant_data[key].append(result['mae'])\n",
    "\n",
    "# Group by main model types\n",
    "model_groups = {'FLRNet': [], 'MLP': [], 'POD': []}\n",
    "for key, maes in model_variant_data.items():\n",
    "    if 'flrnet' in key:\n",
    "        model_groups['FLRNet'].extend(maes)\n",
    "    elif 'mlp' in key:\n",
    "        model_groups['MLP'].extend(maes)\n",
    "    elif 'pod' in key:\n",
    "        model_groups['POD'].extend(maes)\n",
    "\n",
    "box_data = [model_groups[model] for model in ['FLRNet', 'MLP', 'POD'] if model_groups[model]]\n",
    "box_labels = [model for model in ['FLRNet', 'MLP', 'POD'] if model_groups[model]]\n",
    "\n",
    "if box_data:\n",
    "    bp = ax3.boxplot(box_data, labels=box_labels, patch_artist=True)\n",
    "    colors = ['lightblue', 'lightgreen', 'lightcoral']\n",
    "    for patch, color in zip(bp['boxes'], colors[:len(bp['boxes'])]):\n",
    "        patch.set_facecolor(color)\n",
    "\n",
    "ax3.set_ylabel('Mean Squared Error', fontsize=12)\n",
    "ax3.set_title('Model Type Comparison', fontsize=14)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.set_yscale('log')\n",
    "\n",
    "# Plot 4: Performance improvement trend\n",
    "ax4 = axes[1, 1]\n",
    "for model_type in model_types:\n",
    "    improvements = []\n",
    "    sensor_counts_valid = []\n",
    "    \n",
    "    for i, sensor_count in enumerate(sorted(sensor_counts)):\n",
    "        if sensor_count in sensor_count_results and model_type in sensor_count_results[sensor_count]:\n",
    "            all_maes = []\n",
    "            for layout in sensor_count_results[sensor_count][model_type]:\n",
    "                layout_maes = [r['mse'] for r in sensor_count_results[sensor_count][model_type][layout]]\n",
    "                all_maes.extend(layout_maes)\n",
    "            if all_maes:\n",
    "                avg_mse = np.mean(all_maes)\n",
    "                if i == 0:\n",
    "                    improvements.append(0)  # Baseline\n",
    "                else:\n",
    "                    # Calculate improvement percentage\n",
    "                    baseline_mse = np.mean([\n",
    "                        r['mse'] for layout in sensor_count_results[sorted(sensor_counts)[0]][model_type]\n",
    "                        for r in sensor_count_results[sorted(sensor_counts)[0]][model_type][layout]\n",
    "                    ]) if sorted(sensor_counts)[0] in sensor_count_results and model_type in sensor_count_results[sorted(sensor_counts)[0]] else avg_mse\n",
    "                    improvement = (baseline_mse - avg_mse) / baseline_mse * 100\n",
    "                    improvements.append(improvement)\n",
    "                sensor_counts_valid.append(sensor_count)\n",
    "    \n",
    "    if len(improvements) > 1:\n",
    "        ax4.plot(sensor_counts_valid, improvements, 'o-', linewidth=2, markersize=8, \n",
    "                label=model_type.upper())\n",
    "\n",
    "ax4.set_xlabel('Number of Sensors', fontsize=12)\n",
    "ax4.set_ylabel('Performance Improvement (%)', fontsize=12)\n",
    "ax4.set_title('Performance Improvement with More Sensors', fontsize=14)\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "ax4.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('comprehensive_model_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Comprehensive analysis plots created and saved as 'comprehensive_model_analysis.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37e79fc",
   "metadata": {},
   "source": [
    "## Field Reconstruction Visualization\n",
    "\n",
    "Create comprehensive field reconstruction plots with enhanced color maps showing ground truth, predictions, and error distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0c5086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_flrnet_style_field_plot(gt_field, time_indices, Re_value, case_id=0, save_name=None):\n",
    "    \"\"\"Create field reconstruction visualization matching FLRNet training style\"\"\"\n",
    "    n_times = len(time_indices)\n",
    "    \n",
    "    # Define model types to compare as specified\n",
    "    model_types_to_compare = [\n",
    "        'flrnet_fourier_percep',  # FLRNet with Fourier and Perceptual\n",
    "        'flrnet_fourier',         # FLRNet with Fourier only  \n",
    "        'flrnet_percep',          # FLRNet with Perceptual only\n",
    "        'flrnet_standard',        # FLRNet standard (no fourier, no percep)\n",
    "        'mlp',                    # MLP\n",
    "        'pod'                     # POD\n",
    "    ]\n",
    "    \n",
    "    model_labels = [\n",
    "        'FLRNet-FP',\n",
    "        'FLRNet-F',\n",
    "        'FLRNet-P', \n",
    "        'FLRNet-Std',\n",
    "        'MLP',\n",
    "        'POD'\n",
    "    ]\n",
    "    \n",
    "    # Use colorbar range from ground truth data for consistency\n",
    "    global_vmin = np.min(gt_field[:, :, :, case_id])\n",
    "    global_vmax = np.max(gt_field[:, :, :, case_id])\n",
    "    print(f\"Ground truth colorbar range: [{global_vmin:.6f}, {global_vmax:.6f}]\")\n",
    "    \n",
    "    # Create subplots - 1 row for ground truth + 6 rows for models\n",
    "    n_rows = 7\n",
    "    fig, axes = plt.subplots(n_rows, n_times, figsize=(3*n_times, 1.7*n_rows))\n",
    "    if n_times == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "\n",
    "    # Time step labels for 5 columns\n",
    "    time_labels = [f't={round((idx+1)*0.0511, 2)} [s]' for idx in time_indices]  # Rounded to 2 decimal points    \n",
    "\n",
    "    # Plot ground truth using FLRNet training style with global colorbar range\n",
    "    for j, time_idx in enumerate(time_indices):\n",
    "        im_gt = axes[0, j].imshow(gt_field[time_idx, :, :, case_id], \n",
    "                                cmap='RdBu_r', origin='lower', \n",
    "                                vmin=global_vmin, vmax=global_vmax)\n",
    "        axes[0, j].set_title(time_labels[j], fontsize=14, fontweight='normal')\n",
    "        axes[0, j].set_xticks([])\n",
    "        axes[0, j].set_yticks([])\n",
    "        # Remove all spines\n",
    "        for spine in axes[0, j].spines.values():\n",
    "            spine.set_visible(False)\n",
    "\n",
    "    # Add ground truth label\n",
    "    fig.text(-0.01, 0.88, 'Ground Truth', rotation=90, va='center', ha='center', \n",
    "            fontsize=14, fontweight='bold')\n",
    "\n",
    "    # Add a single colorbar for all plots\n",
    "    # Add a single colorbar for all plots\n",
    "    cbar_ax = fig.add_axes([1.01, 0.25, 0.02, 0.5])  # [left, bottom, width, height]\n",
    "    cbar = fig.colorbar(im_gt, cax=cbar_ax)\n",
    "    cbar.set_label('Velocity (m/s)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Find and plot reconstructions for each model type - specifically for random layout and 32 sensors\n",
    "    for i, (model_type, model_label) in enumerate(zip(model_types_to_compare, model_labels)):\n",
    "        row = i + 1\n",
    "        \n",
    "        # Find the best matching model with random layout and 32 sensors\n",
    "        recon_field = None\n",
    "        selected_file = None\n",
    "        \n",
    "        if model_type in organized_data and organized_data[model_type]:\n",
    "            for file_name, file_info in organized_data[model_type].items():\n",
    "                info = file_info['info']\n",
    "                # Check for random layout and 32 sensors\n",
    "                if (info['sensor_layout'] == 'random' and info['num_sensors'] == 32):\n",
    "                    recon_field = file_info['data']['predictions']\n",
    "                    selected_file = file_name\n",
    "                    print(f\"Selected {model_type}: {file_name} (layout: {info['sensor_layout']}, sensors: {info['num_sensors']})\")\n",
    "                    break\n",
    "            \n",
    "            # If no random_32 found, try to find any random layout\n",
    "            if recon_field is None:\n",
    "                for file_name, file_info in organized_data[model_type].items():\n",
    "                    info = file_info['info']\n",
    "                    if info['sensor_layout'] == 'random':\n",
    "                        recon_field = file_info['data']['predictions']\n",
    "                        selected_file = file_name\n",
    "                        print(f\"Fallback {model_type}: {file_name} (layout: {info['sensor_layout']}, sensors: {info['num_sensors']})\")\n",
    "                        break\n",
    "            \n",
    "            # If still no random layout found, use first available\n",
    "            if recon_field is None:\n",
    "                first_file = list(organized_data[model_type].keys())[0]\n",
    "                recon_field = organized_data[model_type][first_file]['data']['predictions']\n",
    "                selected_file = first_file\n",
    "                info = organized_data[model_type][first_file]['info']\n",
    "                print(f\"Default {model_type}: {first_file} (layout: {info['sensor_layout']}, sensors: {info['num_sensors']})\")\n",
    "        \n",
    "        # Plot reconstruction using FLRNet training style with global colorbar range\n",
    "        for j, time_idx in enumerate(time_indices):\n",
    "            if recon_field is not None:\n",
    "                # Reshape if needed\n",
    "                if len(recon_field.shape) == 4 and recon_field.shape[3] > recon_field.shape[0]:\n",
    "                    recon_field = np.transpose(recon_field, (3, 1, 2, 0))\n",
    "                \n",
    "                if time_idx < recon_field.shape[0]:\n",
    "                    im_recon = axes[row, j].imshow(recon_field[time_idx, :, :, case_id], \n",
    "                                                  cmap='RdBu_r', origin='lower',\n",
    "                                                  vmin=global_vmin, vmax=global_vmax)\n",
    "                else:\n",
    "                    # Show placeholder if time index out of range\n",
    "                    axes[row, j].text(0.5, 0.5, 'N/A', ha='center', va='center', \n",
    "                                    transform=axes[row, j].transAxes, fontsize=10)\n",
    "            else:\n",
    "                # Show placeholder if no data\n",
    "                axes[row, j].text(0.5, 0.5, 'No Data', ha='center', va='center', \n",
    "                                transform=axes[row, j].transAxes, fontsize=10)\n",
    "            \n",
    "            axes[row, j].set_xticks([])\n",
    "            axes[row, j].set_yticks([])\n",
    "            # Remove all spines\n",
    "            for spine in axes[row, j].spines.values():\n",
    "                spine.set_visible(False)\n",
    "            \n",
    "            # # Add colorbar for the last column\n",
    "            # if j == n_times - 1 and recon_field is not None:\n",
    "            #     cbar_recon = plt.colorbar(im_recon, ax=axes[row, j], fraction=0.046, pad=0.04)\n",
    "            #     cbar_recon.set_label('Velocity (m/s)', fontsize=9)\n",
    "        \n",
    "        # Add model label with configuration info\n",
    "        if recon_field is not None and selected_file:\n",
    "            info = None\n",
    "            for category_data in organized_data.values():\n",
    "                if selected_file in category_data:\n",
    "                    info = category_data[selected_file]['info']\n",
    "                    break\n",
    "            label_text = model_label\n",
    "        else:\n",
    "            label_text = f\"{model_label}\\n(No Data)\"\n",
    "            \n",
    "        fig.text(-0.01, 0.88 - row * 0.135, label_text, rotation=90, va='center', ha='center', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Main title\n",
    "    fig.suptitle(f'Flow Field Reconstruction Results in The Case Re = {Re_value}', \n",
    "                 fontsize=18, fontweight='bold', y=1.0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_name:\n",
    "        plt.savefig(f\"{save_name}.png\", dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.savefig(f\"{save_name}.pdf\", dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def create_field_reconstruction_analysis(case_id=0, Re_value=None):\n",
    "    \"\"\"Create field reconstruction visualization using FLRNet training style colormap\"\"\"\n",
    "    if gt_data is None:\n",
    "        print(\"No ground truth data available for field visualization\")\n",
    "        return\n",
    "    \n",
    "    # Select 5 time indices: 1, 10, 20, 30, 39 (0-indexed: 0, 9, 19, 29, 38)\n",
    "    max_time_steps = gt_data.shape[0]  # Total time steps = 39\n",
    "    \n",
    "    # Create 5 evenly distributed time indices with first=1 and last=39\n",
    "    if max_time_steps >= 39:\n",
    "        time_indices = [0, 9, 19, 29, 38] # t=1, t=10, t=20, t=30, t=39 (0-indexed)\n",
    "    else:\n",
    "        # Fallback if we have fewer time steps\n",
    "        time_indices = [0, max_time_steps//4, max_time_steps//2, 3*max_time_steps//4, max_time_steps-1]\n",
    "    if Re_value is not None:\n",
    "        print(\"Creating field reconstruction visualization with FLRNet training style:\")\n",
    "        print(f\"Total time steps available: {max_time_steps}\")\n",
    "        print(f\"Selected time indices (0-indexed): {time_indices}\")\n",
    "        print(f\"Corresponding time steps (1-indexed): {[t+1 for t in time_indices]}\")\n",
    "        print(f\"Reynolds number: {Re_value}\")\n",
    "        print(\"Comparing models: FLRNet variants, MLP, and POD - Random Layout Configuration\")\n",
    "        \n",
    "        # Print available configurations for verification\n",
    "        print(\"\\nAvailable model configurations:\")\n",
    "        for model_type, model_data in organized_data.items():\n",
    "            if model_type != 'ground_truth' and model_data:\n",
    "                print(f\"\\n{model_type}:\")\n",
    "                for file_name, file_info in model_data.items():\n",
    "                    info = file_info['info']\n",
    "                    print(f\"  - {file_name}: {info['sensor_layout']} layout, {info['num_sensors']} sensors\")\n",
    "        \n",
    "        # Create the field plot using FLRNet training style (no error maps)\n",
    "        save_name = f'field_reconstruction_random_{Re_value}'\n",
    "        create_flrnet_style_field_plot(\n",
    "            gt_field=gt_data,\n",
    "            time_indices=time_indices,\n",
    "            Re_value=Re_value,\n",
    "            case_id=case_id,\n",
    "            save_name=save_name\n",
    "        )\n",
    "        \n",
    "        print(\"FLRNet training style field reconstruction visualization completed\")\n",
    "    else:      \n",
    "        print(\"Reynolds number not provided, skipping field reconstruction visualization\")                \n",
    "\n",
    "# Create field reconstruction analysis\n",
    "create_field_reconstruction_analysis(1, Re_value=60)\n",
    "\n",
    "create_field_reconstruction_analysis(3, Re_value=300)\n",
    "\n",
    "create_field_reconstruction_analysis(5, Re_value=950)\n",
    "\n",
    "create_field_reconstruction_analysis(6, Re_value=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deec0989",
   "metadata": {},
   "source": [
    "## Temporal Error Analysis\n",
    "\n",
    "Analyze how reconstruction error evolves over time steps for different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ccf1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_temporal_errors():\n",
    "    \"\"\"Analyze temporal evolution of reconstruction errors - ONLY random_32 data\"\"\"\n",
    "    if gt_data is None:\n",
    "        print(\"No ground truth data available for temporal analysis\")\n",
    "        return\n",
    "    \n",
    "    time_steps = np.arange(gt_data.shape[0])\n",
    "    temporal_mae = {\n",
    "        'flrnet_fourier_percep': [],\n",
    "        'flrnet_fourier': [],\n",
    "        'flrnet_percep': [],\n",
    "        'flrnet_standard': [],\n",
    "        'mlp': [],\n",
    "        'pod': []\n",
    "    }\n",
    "    \n",
    "    print(\"Analyzing temporal errors - ONLY random layout with 32 sensors:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Filter and analyze only random_32 configurations\n",
    "    temporal_mae_direct = {}\n",
    "    \n",
    "    for model_type, model_data in organized_data.items():\n",
    "        if model_type == 'ground_truth' or not model_data:\n",
    "            continue\n",
    "            \n",
    "        # Find files with random layout and 32 sensors ONLY\n",
    "        random_32_files = []\n",
    "        for file_name, file_info in model_data.items():\n",
    "            info = file_info['info']\n",
    "            if info['sensor_layout'] == 'random' and info['num_sensors'] == 32:\n",
    "                random_32_files.append((file_name, file_info))\n",
    "        \n",
    "        if random_32_files:\n",
    "            # Use the first random_32 file found for this model type\n",
    "            file_name, file_info = random_32_files[0]\n",
    "            \n",
    "            if 'predictions' in file_info['data']:\n",
    "                predictions = file_info['data']['predictions']\n",
    "                targets = file_info['data']['targets']\n",
    "                \n",
    "                # Reshape if needed\n",
    "                if len(predictions.shape) == 4 and predictions.shape[3] > predictions.shape[0]:\n",
    "                    predictions = np.transpose(predictions, (3, 1, 2, 0))\n",
    "                    targets = np.transpose(targets, (3, 1, 2, 0))\n",
    "                \n",
    "                # Calculate MAE for each time step\n",
    "                mae_per_time = []\n",
    "                for t in range(min(predictions.shape[0], targets.shape[0])):\n",
    "                    mae_t = np.mean(np.abs(targets[t] - predictions[t]))\n",
    "                    mae_per_time.append(mae_t)\n",
    "                \n",
    "                temporal_mae_direct[model_type] = mae_per_time\n",
    "                print(f\"  ✓ {model_type}: {file_name}\")\n",
    "                print(f\"    Layout: {file_info['info']['sensor_layout']}, Sensors: {file_info['info']['num_sensors']}\")\n",
    "                print(f\"    Time steps analyzed: {len(mae_per_time)}\")\n",
    "            else:\n",
    "                print(f\"  ✗ {model_type}: {file_name} missing predictions/targets\")\n",
    "        else:\n",
    "            print(f\"  ✗ {model_type}: No random_32 configuration found\")\n",
    "    \n",
    "    # Use the filtered temporal data\n",
    "    temporal_mae = temporal_mae_direct\n",
    "    time_steps = np.arange(len(next(iter(temporal_mae.values()), []))) if temporal_mae else []\n",
    "    \n",
    "    return time_steps, temporal_mae\n",
    "\n",
    "# Analyze temporal errors with random_32 filter\n",
    "time_steps, temporal_mae = analyze_temporal_errors()\n",
    "\n",
    "# Create enhanced temporal error plot for random_32 only\n",
    "if any(len(values) > 0 for values in temporal_mae.values()):\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 7))\n",
    "    \n",
    "    # Enhanced styling - updated colors for new model types with better contrast and visibility\n",
    "    # colors = ['#2E86AB', '#E63946', '#F77F00', '#06D6A0', '#8338EC', '#A23B72']  # Professional color palette\n",
    "    markers = ['o', 's', '^', 'D', 'v', 'p']  # More distinct markers\n",
    "    linestyles = ['-', '-', '-', '-', '-', '-']  # All solid lines as requested\n",
    "\n",
    "    # Alternative professional color scheme (uncomment to use):\n",
    "    # colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']  # Matplotlib default (professional)\n",
    "\n",
    "    # Alternative vibrant color scheme (uncomment to use):\n",
    "    colors = ['#0077BE', '#FF6B35', '#004E89', '#FF9F1C', '#7209B7', '#C73E1D']  # High contrast vibrant\n",
    "\n",
    "    # Model labels for display\n",
    "    model_labels = {\n",
    "        'flrnet_fourier_percep': 'FLRNet-FP',\n",
    "        'flrnet_fourier': 'FLRNet-F',\n",
    "        'flrnet_percep': 'FLRNet-P',\n",
    "        'flrnet_standard': 'FLRNet-Std',\n",
    "        'mlp': 'MLP',\n",
    "        'pod': 'POD'\n",
    "    }\n",
    "    \n",
    "    # Plot temporal evolution\n",
    "    for i, (model_type, mae_values) in enumerate(temporal_mae.items()):\n",
    "        if len(mae_values) > 0:\n",
    "            # Subsample for better visualization\n",
    "            step = max(1, len(mae_values) // 20)  # Show ~20 points\n",
    "            t_sub = time_steps[:len(mae_values):step]*0.0511  # Convert to seconds\n",
    "            mae_sub = mae_values[::step]\n",
    "            \n",
    "            ax1.plot(t_sub, mae_sub,\n",
    "                    label=model_labels.get(model_type, model_type),\n",
    "                    color=colors[i],\n",
    "                    linestyle=linestyles[i],\n",
    "                    linewidth=2.5,\n",
    "                    marker=markers[i],\n",
    "                    markersize=6,\n",
    "                    markerfacecolor='white',\n",
    "                    markeredgewidth=2,\n",
    "                    alpha=0.8)\n",
    "    \n",
    "        # Styling\n",
    "    ax1.set_title('Temporal Evolution of Reconstruction Error\\n(Random Layout, 32 Sensors)', \n",
    "                  fontsize=18, fontweight='bold', pad=20)\n",
    "    ax1.set_xlabel('Time [s]', fontsize=14, fontweight='bold')\n",
    "    ax1.set_ylabel('Mean Absolute Error (m/s)', fontsize=14, fontweight='bold')\n",
    "    ax1.legend(loc='upper left', fontsize=14, frameon=True, fancybox=True, shadow=True)\n",
    "    ax1.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax1.tick_params(axis='both', which='major', labelsize=14)\n",
    "    ax1.set_xlim(0, 2)  # Set x-axis limit from 0 to 2\n",
    "    # Add bounding box around the plot\n",
    "    for spine in ax1.spines.values():\n",
    "        spine.set_visible(True)\n",
    "        # spine.set_linewidth(1.5)\n",
    "        # spine.set_color('black')\n",
    "    \n",
    "    # Add secondary y-axis for percentage\n",
    "    ax2 = ax1.twinx()\n",
    "    for i, (model_type, mae_values) in enumerate(temporal_mae.items()):\n",
    "        if len(mae_values) > 0:\n",
    "            step = max(1, len(mae_values) // 20)\n",
    "            t_sub = time_steps[:len(mae_values):step]*0.0511  # Convert to seconds\n",
    "            mae_sub = np.array(mae_values[::step])\n",
    "            mae_percentage = mae_sub / max_val * 100\n",
    "            \n",
    "            ax2.plot(t_sub, mae_percentage,\n",
    "                    color=colors[i],\n",
    "                    linestyle=linestyles[i],\n",
    "                    linewidth=2.5,\n",
    "                    marker=markers[i],\n",
    "                    markersize=6,\n",
    "                    markerfacecolor='white',\n",
    "                    markeredgewidth=2,\n",
    "                    alpha=0.6)\n",
    "    \n",
    "    ax2.set_ylabel('Mean Absolute Percentage Error (%)', fontsize=14, fontweight='bold')\n",
    "    ax2.tick_params(axis='y', labelsize=14)\n",
    "    \n",
    "    # Ensure secondary axis also has visible spines\n",
    "    for spine in ax2.spines.values():\n",
    "        spine.set_visible(True)\n",
    "        # spine.set_linewidth(1.5)\n",
    "        # spine.set_color('black')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('temporal_error_analysis_random_32_only.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.savefig('temporal_error_analysis_random_32_only.pdf', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Temporal error analysis completed (random_32 only)\")\n",
    "    print(f\"Models analyzed: {list(temporal_mae.keys())}\")\n",
    "    print(f\"Files used: random layout, 32 sensors configuration only\")\n",
    "else:\n",
    "    print(\"No random_32 data available for temporal analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092c8bcf",
   "metadata": {},
   "source": [
    "## Vertical Error Profile Analysis\n",
    "\n",
    "Create vertical profile plots showing error distribution across the flow field domain at different positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2712f2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vertical_error_profiles():\n",
    "    \"\"\"Create vertical error profiles at different positions - PDF style with averaged errors across all time steps and cases\"\"\"\n",
    "    if gt_data is None:\n",
    "        print(\"No ground truth data available for vertical error profile analysis\")\n",
    "        return\n",
    "    \n",
    "    # Define positions along x-axis for vertical profiles\n",
    "    positions = [1, 2, 3, 4, 5, 6]  # 6 positions as in original\n",
    "    # Normalize vertical coordinate to range [0, 1] [m]\n",
    "    y_coords = np.linspace(0, 1, gt_data.shape[1])\n",
    "    \n",
    "    print(f\"Creating vertical error profiles averaged across all time steps and cases (channel 0 and last channel)\")\n",
    "    print(f\"Using ONLY random_32 configurations\")\n",
    "    print(f\"Positions: {positions}\")\n",
    "    print(f\"Available time steps: {gt_data.shape[0]}\")\n",
    "    print(f\"Available cases (channels): {gt_data.shape[3]}\")\n",
    "    \n",
    "    # Create subplots for multiple positions\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for pos_idx, pos in enumerate(positions):\n",
    "        if pos_idx >= len(axes):\n",
    "            break\n",
    "            \n",
    "        ax = axes[pos_idx]\n",
    "        x_pos = int(gt_data.shape[2] / 7 * pos)  # Map position to grid coordinates\n",
    "        x_pos_real = x_pos * 0.0078125  # Real x-coordinate in meters\n",
    "        \n",
    "        # Enhanced styling for PDF with distinct colors and markers\n",
    "        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "        markers = ['o', 's', '^', 'D', 'v', 'p']  # Different markers for each model\n",
    "        \n",
    "        # Model profiles - calculate averaged error profiles across all time steps and cases\n",
    "        model_types = ['flrnet_fourier_percep', 'flrnet_fourier', 'flrnet_percep', 'flrnet_standard', 'mlp', 'pod']\n",
    "        model_labels = ['FLRNet-FP', 'FLRNet-F', 'FLRNet--P', 'FLRNet-Std', 'MLP', 'POD']\n",
    "        \n",
    "        for i, (model_type, model_label) in enumerate(zip(model_types, model_labels)):\n",
    "            # Find the corresponding model data from organized_data - ONLY random_32\n",
    "            recon_field = None\n",
    "            selected_file = None\n",
    "            \n",
    "            if model_type in organized_data and organized_data[model_type]:\n",
    "                # Look for random_32 configuration specifically\n",
    "                for file_name, file_info in organized_data[model_type].items():\n",
    "                    info = file_info['info']\n",
    "                    if info['sensor_layout'] == 'random' and info['num_sensors'] == 32:\n",
    "                        recon_field = file_info['data']['predictions']\n",
    "                        selected_file = file_name\n",
    "                        print(f\"  Using {model_type}: {file_name} (random_32)\")\n",
    "                        break\n",
    "                \n",
    "                if recon_field is None:\n",
    "                    print(f\"  ✗ {model_type}: No random_32 configuration found\")\n",
    "                    continue\n",
    "            \n",
    "            if recon_field is not None:\n",
    "                # Reshape if needed\n",
    "                if len(recon_field.shape) == 4 and recon_field.shape[3] > recon_field.shape[0]:\n",
    "                    recon_field = np.transpose(recon_field, (3, 1, 2, 0))\n",
    "                \n",
    "                # Get ground truth for the same position\n",
    "                gt_profiles_all = gt_data[:, :, x_pos, :]  # Shape: (time, height, cases)\n",
    "                recon_profiles_all = recon_field[:, :, x_pos, :]  # Shape: (time, height, cases)\n",
    "                \n",
    "                # Calculate error profiles for all time steps and cases\n",
    "                all_error_profiles = []\n",
    "                \n",
    "                # Use channel 0 and last channel only\n",
    "                channels_to_use = [0, gt_data.shape[3] - 1]\n",
    "                \n",
    "                for time_step in range(min(gt_data.shape[0], recon_field.shape[0])):\n",
    "                    for channel in channels_to_use:\n",
    "                        if channel < gt_data.shape[3] and channel < recon_field.shape[3]:\n",
    "                            gt_profile = gt_data[time_step, :, x_pos, channel]\n",
    "                            recon_profile = recon_field[time_step, :, x_pos, channel]\n",
    "                            \n",
    "                            # Calculate absolute error profile\n",
    "                            error_profile = np.abs(gt_profile - recon_profile)\n",
    "                            all_error_profiles.append(error_profile)\n",
    "                \n",
    "                if all_error_profiles:\n",
    "                    # Average across all time steps and cases\n",
    "                    averaged_error_profile = np.mean(all_error_profiles, axis=0)\n",
    "                    \n",
    "                    ax.plot(y_coords, averaged_error_profile, label=model_label, \n",
    "                           color=colors[i], linestyle='-', linewidth=1.5, \n",
    "                           marker=markers[i], markersize=3, markevery=5,\n",
    "                           markerfacecolor='white', markeredgewidth=1, alpha=0.8)\n",
    "                    \n",
    "                    print(f\"    ✓ Averaged {len(all_error_profiles)} error profiles (time steps × cases)\")\n",
    "                else:\n",
    "                    print(f\"    ✗ No valid error profiles calculated for {model_type}\")\n",
    "        \n",
    "        # Styling for each subplot - PDF style\n",
    "        ax.set_title(f'Horizontal coordinate \\n {x_pos_real:.4f} [m]', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel('Vertical Coordinate [m]', fontsize=14, fontweight='bold')\n",
    "        ax.set_ylabel('Averaged Absolute Error [m/s]', fontsize=14, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "        ax.tick_params(axis='both', labelsize=12)\n",
    "        ax.spines['top'].set_visible(True)\n",
    "        ax.spines['right'].set_visible(True)\n",
    "        \n",
    "        # Set y-axis to start from 0 for error visualization\n",
    "        ax.set_ylim(bottom=0)\n",
    "        \n",
    "        # Add legend only to the first subplot\n",
    "        if pos_idx == 0:\n",
    "            ax.legend(loc='upper right', fontsize=10, frameon=True)\n",
    "    \n",
    "    plt.suptitle('Average Vertical Absolute Error Profiles \\nRandom Layout, 32 Sensors', \n",
    "                 fontsize=16, fontweight='bold', y=1.0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('vertical_error_profiles_averaged_random_32.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.savefig('vertical_error_profiles_averaged_random_32.pdf', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Vertical error profile analysis completed (averaged across all time steps and cases, random_32 only)\")\n",
    "\n",
    "# Call the updated error profile function\n",
    "create_vertical_error_profiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4da997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_domain_with_annotated_slices():\n",
    "    \"\"\"Create domain visualization with simplified drawing showing obstacle and slice positions\"\"\"\n",
    "    if gt_data is None:\n",
    "        print(\"No ground truth data available for domain visualization\")\n",
    "        return\n",
    "    \n",
    "    # Define domain parameters\n",
    "    nx, ny = gt_data.shape[2], gt_data.shape[1]\n",
    "    Lx, Ly = 2.0, 1.0  # Domain dimensions in meters\n",
    "    dx, dy = Lx / nx, Ly / ny\n",
    "    \n",
    "    # Obstacle parameters\n",
    "    obstacle_center_x = 0.5  # 0.5 m from left\n",
    "    obstacle_center_y = 0.5  # 0.5 m from bottom\n",
    "    obstacle_diameter = 0.25  # 0.25 m diameter\n",
    "    obstacle_radius = obstacle_diameter / 2\n",
    "    \n",
    "    # Slice positions (same as error profile analysis)\n",
    "    positions = [1, 2, 3, 4, 5, 6]\n",
    "    slice_colors = [\"#000000\", \"#000000\", \"#000000\", \"#000000\", \"#000000\", '#000000']\n",
    "    \n",
    "    # Create the figure with proper aspect ratio\n",
    "    # Calculate figure size to maintain proper aspect ratio (2:1 for domain)\n",
    "    fig_width = 12  # Base width\n",
    "    fig_height = fig_width * (Ly / Lx)  # Maintain domain aspect ratio\n",
    "    fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "    \n",
    "    # Draw domain boundaries with light gray fill\n",
    "    domain_rect = plt.Rectangle((0, 0), Lx, Ly, \n",
    "                               facecolor='lightgray', edgecolor='black', \n",
    "                               linewidth=3, alpha=0.3)\n",
    "    ax.add_patch(domain_rect)\n",
    "    \n",
    "    # Draw the circular obstacle\n",
    "    obstacle_circle = plt.Circle((obstacle_center_x, obstacle_center_y), obstacle_radius,\n",
    "                                facecolor='darkgray', edgecolor='black', \n",
    "                                linewidth=2, alpha=0.8)\n",
    "    ax.add_patch(obstacle_circle)\n",
    "    \n",
    "    # Mark and annotate slice positions\n",
    "    for i, pos in enumerate(positions):\n",
    "        # Calculate x-position\n",
    "        x_pos_index = int(nx / 7 * pos)\n",
    "        x_pos_real = x_pos_index * dx\n",
    "        \n",
    "        # Draw vertical slice line\n",
    "        ax.axvline(x=x_pos_real, color=slice_colors[i], linewidth=4, \n",
    "                  linestyle='-', alpha=0.9, zorder=5)\n",
    "        \n",
    "        # Add position markers at top and bottom\n",
    "        ax.plot(x_pos_real, Ly, marker='v', color=slice_colors[i], \n",
    "               markersize=20, markeredgecolor='white', markeredgewidth=2, zorder=6)\n",
    "        ax.plot(x_pos_real, 0, marker='^', color=slice_colors[i], \n",
    "               markersize=20, markeredgecolor='white', markeredgewidth=2, zorder=6)\n",
    "        \n",
    "        # Add position labels\n",
    "        ax.text(x_pos_real, Ly + 0.18, f'Slice {pos}\\nx={x_pos_real:.3f}m', \n",
    "               ha='center', va='bottom', fontsize=15, fontweight='bold',\n",
    "               color=slice_colors[i], alpha=0.9)\n",
    "    \n",
    "    # Set equal aspect ratio to maintain circle shape\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "    # Set limits to show the domain properly\n",
    "    ax.set_xlim(-0.1, Lx + 0.1)\n",
    "    ax.set_ylim(-0.1, Ly + 0.15)  # Extra space for labels\n",
    "    \n",
    "    # Remove axes but keep the proper scaling\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    # Remove spines\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('domain_with_error_profile_slices.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.savefig('domain_with_error_profile_slices.pdf', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed slice information\n",
    "    print(\"Domain and Slice Information:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Physical domain: {Lx:.1f} × {Ly:.1f} m\")\n",
    "    print(f\"Grid resolution: {nx} × {ny} points\")\n",
    "    print(f\"Grid spacing: Δx = {dx:.6f} m, Δy = {dy:.6f} m\")\n",
    "    print(f\"Obstacle: Circular, diameter = {obstacle_diameter:.2f} m\")\n",
    "    print(f\"Obstacle position: ({obstacle_center_x:.1f}, {obstacle_center_y:.1f}) m\")\n",
    "    print(f\"Reynolds number: ~750 (estimated)\")\n",
    "    print()\n",
    "    print(\"Vertical slice positions for error profile analysis:\")\n",
    "    for i, pos in enumerate(positions):\n",
    "        x_pos_index = int(nx / 7 * pos)\n",
    "        x_pos_real = x_pos_index * dx\n",
    "        print(f\"  Slice {pos}: Grid index {x_pos_index:3d} → x = {x_pos_real:.4f} m → Color: {slice_colors[i]}\")\n",
    "    print()\n",
    "    print(\"These slices correspond to the vertical error profiles shown in previous analysis.\")\n",
    "    print(\"Error profiles are averaged across all time steps and specified cases.\")\n",
    "\n",
    "# Create the annotated domain visualization\n",
    "create_domain_with_annotated_slices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbfba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_spectral_bias_all_random_cases_all_timesteps():\n",
    "    \"\"\"Analyze spectral bias for all models using all random configurations across different Reynolds numbers and ALL time steps\"\"\"\n",
    "    from spectral_bias import spectral_bias\n",
    "    \n",
    "    if gt_data is None:\n",
    "        print(\"No ground truth data available for spectral bias analysis\")\n",
    "        return\n",
    "    \n",
    "    print(\"Computing Spectral Bias for All Models - All Random Layout Configurations - ALL TIME STEPS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Reynolds numbers corresponding to each channel\n",
    "    reynolds_numbers = [30, 60, 120, 300, 700, 950, 3000, 8000]\n",
    "    total_channels = gt_data.shape[3]\n",
    "    \n",
    "    # Ensure we don't exceed available channels\n",
    "    if len(reynolds_numbers) > total_channels:\n",
    "        reynolds_numbers = reynolds_numbers[:total_channels]\n",
    "    \n",
    "    # Model types to analyze\n",
    "    model_types = ['flrnet_fourier_percep', 'flrnet_fourier', 'flrnet_percep', 'flrnet_standard', 'mlp', 'pod']\n",
    "    model_labels = ['FLRNet-FP', 'FLRNet-F', 'FLRNet-P', 'FLRNet-Std', 'MLP', 'POD']\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "    markers = ['o', 's', '^', 'D', 'v', 'p']\n",
    "    \n",
    "    # Store spectral bias data\n",
    "    spectral_bias_data = {}\n",
    "    \n",
    "    print(f\"Reynolds numbers to analyze: {reynolds_numbers}\")\n",
    "    print(f\"Time steps used for analysis: ALL ({gt_data.shape[0]} time steps)\")\n",
    "    print()\n",
    "    \n",
    "    # Process each model\n",
    "    for model_type, model_label in zip(model_types, model_labels):\n",
    "        print(f\"Processing {model_label}...\")\n",
    "        \n",
    "        # Find ALL random configurations for this model type\n",
    "        random_configs = []\n",
    "        \n",
    "        if model_type in organized_data and organized_data[model_type]:\n",
    "            for file_name, file_info in organized_data[model_type].items():\n",
    "                info = file_info['info']\n",
    "                if info['sensor_layout'] == 'random':  # Any random layout, any sensor count\n",
    "                    random_configs.append({\n",
    "                        'file_name': file_name,\n",
    "                        'data': file_info['data'],\n",
    "                        'num_sensors': info['num_sensors']\n",
    "                    })\n",
    "                    print(f\"  Found: {file_name} (sensors: {info['num_sensors']})\")\n",
    "            \n",
    "            if not random_configs:\n",
    "                print(f\"  ✗ No random configurations found\")\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"  ✗ No data available\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate spectral bias for each Reynolds number, averaging across all random configs and ALL time steps\n",
    "        reynolds_sb_list = []\n",
    "        \n",
    "        for i, re_num in enumerate(reynolds_numbers):\n",
    "            ch = i  # Channel index (0-indexed)\n",
    "            config_sb_values = []\n",
    "            \n",
    "            # Process each random configuration\n",
    "            for config in random_configs:\n",
    "                recon_field = config['data']['predictions']\n",
    "                \n",
    "                # Reshape if needed\n",
    "                if len(recon_field.shape) == 4 and recon_field.shape[3] > recon_field.shape[0]:\n",
    "                    recon_field = np.transpose(recon_field, (3, 1, 2, 0))\n",
    "                \n",
    "                if ch < gt_data.shape[3] and ch < recon_field.shape[3]:\n",
    "                    try:\n",
    "                        # Calculate spectral bias for ALL time steps\n",
    "                        timestep_sb_values = []\n",
    "                        \n",
    "                        for time_step in range(min(gt_data.shape[0], recon_field.shape[0])):\n",
    "                            # Get ground truth and prediction for this Reynolds number at this time step\n",
    "                            gt_field = gt_data[time_step, :, :, ch]  # Shape: (height, width)\n",
    "                            pred_field = recon_field[time_step, :, :, ch]  # Shape: (height, width)\n",
    "                            \n",
    "                            # Compute spectral bias using the imported function\n",
    "                            sb = spectral_bias(gt_field, pred_field, sigma=5)\n",
    "                            timestep_sb_values.append(sb)\n",
    "                        \n",
    "                        # Average spectral bias across all time steps for this configuration\n",
    "                        if timestep_sb_values:\n",
    "                            avg_sb_timesteps = np.mean(timestep_sb_values)\n",
    "                            config_sb_values.append(avg_sb_timesteps)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"    Re = {re_num}, Config {config['file_name']}: Error computing SB - {e}\")\n",
    "                        continue\n",
    "            \n",
    "            # Average spectral bias across all random configurations for this Reynolds number\n",
    "            if config_sb_values:\n",
    "                avg_sb = np.mean(config_sb_values)\n",
    "                std_sb = np.std(config_sb_values)\n",
    "                reynolds_sb_list.append(avg_sb)\n",
    "                print(f\"    Re = {re_num}: SB = {avg_sb:.6f} ± {std_sb:.6f} (n={len(config_sb_values)} configs, {gt_data.shape[0]} timesteps)\")\n",
    "            else:\n",
    "                reynolds_sb_list.append(np.nan)\n",
    "                print(f\"    Re = {re_num}: No valid data\")\n",
    "        \n",
    "        spectral_bias_data[model_type] = {\n",
    "            'model_label': model_label,\n",
    "            'reynolds_sb': reynolds_sb_list,\n",
    "            'num_configs': len(random_configs)\n",
    "        }\n",
    "        print(f\"  Total random configurations used: {len(random_configs)}\")\n",
    "        print()\n",
    "    \n",
    "    # Create spectral bias plot\n",
    "    if spectral_bias_data:\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        \n",
    "        # Plot lines for each model\n",
    "        for i, (model_type, data) in enumerate(spectral_bias_data.items()):\n",
    "            model_label = data['model_label']\n",
    "            reynolds_sb = data['reynolds_sb']\n",
    "            num_configs = data['num_configs']\n",
    "            \n",
    "            # Filter out NaN values\n",
    "            valid_reynolds = []\n",
    "            valid_sb = []\n",
    "            for re_num, sb in zip(reynolds_numbers, reynolds_sb):\n",
    "                if not np.isnan(sb):\n",
    "                    valid_reynolds.append(re_num)\n",
    "                    valid_sb.append(sb)\n",
    "            \n",
    "            if valid_sb:\n",
    "                # Update label to show number of configurations averaged\n",
    "                label_with_count = f\"{model_label}\"\n",
    "                \n",
    "                ax.plot(valid_reynolds, valid_sb, \n",
    "                       label=label_with_count,\n",
    "                       color=colors[i],\n",
    "                       marker=markers[i],\n",
    "                       markersize=10,\n",
    "                       linewidth=3,\n",
    "                       markerfacecolor='white',\n",
    "                       markeredgewidth=2,\n",
    "                       markeredgecolor=colors[i],\n",
    "                       alpha=0.9)\n",
    "        \n",
    "        # Add horizontal line at SB = 0 for reference\n",
    "        ax.axhline(y=0, color='black', linestyle='--', alpha=0.7, linewidth=2)\n",
    "        ax.text(reynolds_numbers[0]*1.1, 0.05, 'SB = 0 (Equal bias)', fontsize=12, alpha=0.7)\n",
    "        \n",
    "        # Styling\n",
    "        ax.set_xlabel('Reynolds Number', fontsize=16, fontweight='bold')\n",
    "        ax.set_ylabel('Spectral Bias', fontsize=16, fontweight='bold')\n",
    "        ax.set_title('Spectral Bias Across Different Reynolds Numbers', \n",
    "                     fontsize=18, fontweight='bold', pad=20)\n",
    "        \n",
    "        # Set x-axis to show all Reynolds numbers with log scale\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xticks(reynolds_numbers)\n",
    "        ax.set_xticklabels([str(re) for re in reynolds_numbers])\n",
    "        \n",
    "        # Add grid and legend\n",
    "        ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)\n",
    "        ax.legend(loc='best', fontsize=14, frameon=True, fancybox=True, shadow=True)\n",
    "        ax.tick_params(axis='both', labelsize=14)\n",
    "        \n",
    "        # # Add explanation text box\n",
    "        # explanation = (\"Spectral Bias Interpretation:\\n\"\n",
    "        #               \"SB > 0: High-frequency bias (missing fine details)\\n\"\n",
    "        #               \"SB < 0: Low-frequency bias (over-smoothing)\\n\"\n",
    "        #               \"SB ≈ 0: Balanced frequency representation\\n\"\n",
    "        #               \"Values averaged across all random configs and all time steps\")\n",
    "        \n",
    "        # ax.text(0.02, 0.98, explanation, transform=ax.transAxes, fontsize=11,\n",
    "        #         verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "        \n",
    "        # Add bounding box\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(True)\n",
    "            spine.set_linewidth(0.5)\n",
    "            spine.set_color('black')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('spectral_bias_across_reynolds_all_random_all_timesteps.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.savefig('spectral_bias_across_reynolds_all_random_all_timesteps.pdf', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.show()\n",
    "        \n",
    "        # Print summary statistics\n",
    "        print(\"Spectral Bias Analysis Summary (All Random Configurations, All Time Steps)\")\n",
    "        print(\"=\" * 85)\n",
    "        print(f\"{'Model':<18} {'Configs':<8} {'Min SB':<10} {'Max SB':<10} {'Range':<10} {'Avg SB':<10}\")\n",
    "        print(\"-\" * 85)\n",
    "        \n",
    "        for model_type, data in spectral_bias_data.items():\n",
    "            model_label = data['model_label']\n",
    "            num_configs = data['num_configs']\n",
    "            reynolds_sb = [sb for sb in data['reynolds_sb'] if not np.isnan(sb)]\n",
    "            \n",
    "            if reynolds_sb:\n",
    "                min_sb = np.min(reynolds_sb)\n",
    "                max_sb = np.max(reynolds_sb)\n",
    "                range_sb = max_sb - min_sb\n",
    "                avg_sb = np.mean(reynolds_sb)\n",
    "                \n",
    "                print(f\"{model_label:<18} {num_configs:<8} {min_sb:<10.6f} {max_sb:<10.6f} {range_sb:<10.6f} {avg_sb:<10.6f}\")\n",
    "        \n",
    "        print(\"\\nReynolds Number-wise Average Spectral Bias (across all models and configs):\")\n",
    "        print(\"-\" * 75)\n",
    "        for i, re_num in enumerate(reynolds_numbers):\n",
    "            re_sb = [data['reynolds_sb'][i] for data in spectral_bias_data.values() \n",
    "                    if i < len(data['reynolds_sb']) and not np.isnan(data['reynolds_sb'][i])]\n",
    "            if re_sb:\n",
    "                avg_re_sb = np.mean(re_sb)\n",
    "                std_re_sb = np.std(re_sb)\n",
    "                bias_type = \"High-freq bias\" if avg_re_sb > 0 else \"Low-freq bias\" if avg_re_sb < 0 else \"Balanced\"\n",
    "                print(f\"Re = {re_num:4d}: {avg_re_sb:8.6f} ± {std_re_sb:6.6f} ({bias_type})\")\n",
    "        \n",
    "        # Summary of configurations used\n",
    "        print(f\"\\nConfiguration Summary:\")\n",
    "        print(\"-\" * 60)\n",
    "        total_configs = sum(data['num_configs'] for data in spectral_bias_data.values())\n",
    "        total_samples = total_configs * gt_data.shape[0]  # configs × time steps\n",
    "        print(f\"Total random configurations analyzed: {total_configs}\")\n",
    "        print(f\"Total time steps per configuration: {gt_data.shape[0]}\")\n",
    "        print(f\"Total spectral bias samples: {total_samples}\")\n",
    "        for model_type, data in spectral_bias_data.items():\n",
    "            if data['num_configs'] > 0:\n",
    "                samples_per_model = data['num_configs'] * gt_data.shape[0]\n",
    "                print(f\"  {data['model_label']}: {data['num_configs']} configs × {gt_data.shape[0]} timesteps = {samples_per_model} samples\")\n",
    "        \n",
    "        print(\"\\nSpectral Bias Interpretation Guide:\")\n",
    "        print(\"- Positive SB: Model has high-frequency bias (captures fine details but may miss smooth variations)\")\n",
    "        print(\"- Negative SB: Model has low-frequency bias (captures smooth variations but may miss fine details)\")\n",
    "        print(\"- SB near 0: Model has balanced frequency representation\")\n",
    "        print(\"- Magnitude indicates severity of bias\")\n",
    "        print(\"- Values represent averages across all available random sensor configurations and ALL time steps\")\n",
    "        print(\"- This provides a more comprehensive temporal assessment of spectral bias\")\n",
    "        \n",
    "        return spectral_bias_data\n",
    "    else:\n",
    "        print(\"No random configurations available for spectral bias analysis\")\n",
    "        return None\n",
    "\n",
    "# Run the spectral bias analysis for all random cases using ALL time steps\n",
    "spectral_bias_results_all_random_all_timesteps = analyze_spectral_bias_all_random_cases_all_timesteps()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531d8ea7",
   "metadata": {},
   "source": [
    "## Summary and Conclusions\n",
    "\n",
    "This notebook provides a comprehensive analysis of flow field reconstruction results with enhanced visualizations and improved color mapping for better interpretation of model performance across different conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b201d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_comprehensive_summary():\n",
    "    \"\"\"Print comprehensive summary of all analyses\"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"COMPREHENSIVE FLOW FIELD RECONSTRUCTION ANALYSIS SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"\\nDATA OVERVIEW:\")\n",
    "    print(f\"  • Ground truth data shape: {gt_data.shape if gt_data is not None else 'Not available'}\")\n",
    "    print(f\"  • Normalization range: [{min_val:.3f}, {max_val:.3f}]\")\n",
    "    print(f\"  • Total inference files processed: {len(inference_data)}\")\n",
    "    \n",
    "    print(f\"\\nMODEL RESULTS SUMMARY:\")\n",
    "    for model_type in ['flrnet', 'flrnet_fourier', 'mlp', 'pod']:\n",
    "        count = len(model_results.get(model_type, []))\n",
    "        print(f\"  • {model_type.replace('_', ' ').title()}: {count} results\")\n",
    "        \n",
    "        if count > 0 and model_type in error_metrics:\n",
    "            mae_values = [metrics['mae'] for metrics in error_metrics[model_type]]\n",
    "            if mae_values:\n",
    "                avg_mae = np.mean(mae_values)\n",
    "                std_mae = np.std(mae_values)\n",
    "                print(f\"    - Average MAE: {avg_mae:.6f} ± {std_mae:.6f} m/s\")\n",
    "                print(f\"    - MAPE: {avg_mae/max_val*100:.3f}%\")\n",
    "    \n",
    "    print(f\"\\nVISUALIZATIONS CREATED:\")\n",
    "    print(f\"  • Enhanced sensor count effect analysis\")\n",
    "    print(f\"  • Enhanced sensor layout comparison\")\n",
    "    print(f\"  • Field reconstruction visualization with improved color maps\")\n",
    "    print(f\"  • Temporal error evolution analysis\")\n",
    "    print(f\"  • Vertical error profile analysis\")\n",
    "    \n",
    "    print(f\"\\nCOLOR SCHEME ENHANCEMENTS:\")\n",
    "    print(f\"  • Enhanced field visualization colormap with better contrast\")\n",
    "    print(f\"  • Improved diverging colormap for error visualization\")\n",
    "    print(f\"  • Consistent color coding across all plots\")\n",
    "    print(f\"  • High-resolution output (300 DPI) for publication quality\")\n",
    "    \n",
    "    print(f\"\\nKEY FINDINGS:\")\n",
    "    if any(len(model_results[model]) > 0 for model in model_results):\n",
    "        print(f\"  • Successfully analyzed multiple model architectures\")\n",
    "        print(f\"  • Enhanced visualizations provide better insight into model performance\")\n",
    "        print(f\"  • Improved color mapping reveals fine details in reconstruction quality\")\n",
    "    else:\n",
    "        print(f\"  • Limited data available for comprehensive analysis\")\n",
    "        print(f\"  • Framework ready for analysis when inference results are available\")\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "\n",
    "# Print comprehensive summary\n",
    "print_comprehensive_summary()\n",
    "\n",
    "# Additional utility function for custom analysis\n",
    "def create_custom_analysis_plot():\n",
    "    \"\"\"Template function for custom analysis plots\"\"\"\n",
    "    print(\"\\nCustom Analysis Template:\")\n",
    "    print(\"This function can be modified to create specific analysis plots\")\n",
    "    print(\"based on your research requirements.\")\n",
    "    \n",
    "    # Example: Create a performance heatmap\n",
    "    if len(model_results['flrnet']) > 0:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        # Placeholder for heatmap data\n",
    "        # This would be filled with actual analysis results\n",
    "        data = np.random.rand(4, 4)  # Example data\n",
    "        \n",
    "        im = ax.imshow(data, cmap='RdYlBu_r', aspect='auto')\n",
    "        \n",
    "        # Styling\n",
    "        ax.set_title('Model Performance Heatmap (Template)', \n",
    "                     fontsize=16, fontweight='bold')\n",
    "        ax.set_xlabel('Configuration', fontsize=14, fontweight='bold')\n",
    "        ax.set_ylabel('Model Type', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = plt.colorbar(im, ax=ax)\n",
    "        cbar.set_label('Performance Metric', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('custom_analysis_template.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Custom analysis template created!\")\n",
    "\n",
    "# Run custom analysis template\n",
    "create_custom_analysis_plot()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"INFERENCE RESULTS ANALYSIS COMPLETED!\")\n",
    "print(\"=\"*50)\n",
    "print(\"All enhanced visualizations have been generated with improved color schemes.\")\n",
    "print(\"High-resolution PNG and PDF files have been saved for publication use.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645243ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mae_across_channels():\n",
    "    \"\"\"Create line plot showing MAE changes across all Reynolds numbers for each model - random_32 only\"\"\"\n",
    "    if gt_data is None:\n",
    "        print(\"No ground truth data available for Reynolds number MAE analysis\")\n",
    "        return\n",
    "    \n",
    "    print(\"Creating line plot of MAE across Reynolds numbers\")\n",
    "    print(\"Using ONLY random_32 configurations\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Model types to analyze\n",
    "    model_types = ['flrnet_fourier_percep', 'flrnet_fourier', 'flrnet_percep', 'flrnet_standard', 'mlp', 'pod']\n",
    "    model_labels = ['FLRNet-FP', 'FLRNet-F', 'FLRNet-P', 'FLRNet-Std', 'MLP', 'POD']\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "    markers = ['o', 's', '^', 'D', 'v', 'p']\n",
    "    \n",
    "    # Reynolds numbers corresponding to each channel\n",
    "    reynolds_numbers = [30, 60, 120, 300, 700, 950, 3000, 8000]\n",
    "    total_channels = gt_data.shape[3]\n",
    "    \n",
    "    # Ensure we don't exceed available channels\n",
    "    if len(reynolds_numbers) > total_channels:\n",
    "        reynolds_numbers = reynolds_numbers[:total_channels]\n",
    "        print(f\"Warning: Only {total_channels} channels available, using first {len(reynolds_numbers)} Reynolds numbers\")\n",
    "    \n",
    "    print(f\"Reynolds numbers to analyze: {reynolds_numbers}\")\n",
    "    print(f\"Total channels available: {total_channels}\")\n",
    "    print()\n",
    "    \n",
    "    # Store MAE data for each model across Reynolds numbers\n",
    "    mae_data = {}\n",
    "    \n",
    "    for model_type, model_label in zip(model_types, model_labels):\n",
    "        print(f\"Processing {model_label}...\")\n",
    "        \n",
    "        # Find random_32 configuration for this model type\n",
    "        recon_field = None\n",
    "        selected_file = None\n",
    "        \n",
    "        if model_type in organized_data and organized_data[model_type]:\n",
    "            for file_name, file_info in organized_data[model_type].items():\n",
    "                info = file_info['info']\n",
    "                if info['sensor_layout'] == 'random' and info['num_sensors'] == 32:\n",
    "                    recon_field = file_info['data']['predictions']\n",
    "                    selected_file = file_name\n",
    "                    print(f\"  Using: {file_name}\")\n",
    "                    break\n",
    "            \n",
    "            if recon_field is None:\n",
    "                print(f\"  ✗ No random_32 configuration found\")\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"  ✗ No data available\")\n",
    "            continue\n",
    "        \n",
    "        # Reshape if needed\n",
    "        if len(recon_field.shape) == 4 and recon_field.shape[3] > recon_field.shape[0]:\n",
    "            recon_field = np.transpose(recon_field, (3, 1, 2, 0))\n",
    "        \n",
    "        # Calculate MAE for each Reynolds number (channel) across all time steps\n",
    "        reynolds_maes = []\n",
    "        for i, re_num in enumerate(reynolds_numbers):\n",
    "            ch = i  # Channel index (0-indexed)\n",
    "            if ch < gt_data.shape[3] and ch < recon_field.shape[3]:\n",
    "                # Calculate MAE across all time steps for this Reynolds number\n",
    "                channel_errors = []\n",
    "                for t in range(min(gt_data.shape[0], recon_field.shape[0])):\n",
    "                    gt_ch = gt_data[t, :, :, ch]\n",
    "                    pred_ch = recon_field[t, :, :, ch]\n",
    "                    mae_ch = np.mean(np.abs(gt_ch - pred_ch))\n",
    "                    channel_errors.append(mae_ch)\n",
    "                \n",
    "                avg_mae_reynolds = np.mean(channel_errors)\n",
    "                reynolds_maes.append(avg_mae_reynolds)\n",
    "                print(f\"    Re = {re_num}: MAE = {avg_mae_reynolds:.6f}\")\n",
    "            else:\n",
    "                reynolds_maes.append(np.nan)\n",
    "                print(f\"    Re = {re_num}: No data available\")\n",
    "        \n",
    "        mae_data[model_type] = {\n",
    "            'model_label': model_label,\n",
    "            'reynolds_maes': reynolds_maes\n",
    "        }\n",
    "        print()\n",
    "    \n",
    "    # Create the line plot\n",
    "    if mae_data:\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        \n",
    "        # Plot lines for each model\n",
    "        for i, (model_type, data) in enumerate(mae_data.items()):\n",
    "            model_label = data['model_label']\n",
    "            reynolds_maes = data['reynolds_maes']\n",
    "            \n",
    "            # Filter out NaN values\n",
    "            valid_reynolds = []\n",
    "            valid_maes = []\n",
    "            for re_num, mae in zip(reynolds_numbers, reynolds_maes):\n",
    "                if not np.isnan(mae):\n",
    "                    valid_reynolds.append(re_num)\n",
    "                    valid_maes.append(mae)\n",
    "            \n",
    "            if valid_maes:\n",
    "                ax.plot(valid_reynolds, valid_maes, \n",
    "                       label=model_label,\n",
    "                       color=colors[i],\n",
    "                       marker=markers[i],\n",
    "                       markersize=8,\n",
    "                       linewidth=2.5,\n",
    "                       markerfacecolor='white',\n",
    "                       markeredgewidth=2,\n",
    "                       markeredgecolor=colors[i],\n",
    "                       alpha=0.9)\n",
    "        \n",
    "        # Styling\n",
    "        ax.set_xlabel('Reynolds Number', fontsize=16, fontweight='bold')\n",
    "        ax.set_ylabel('Mean Absolute Error [m/s]', fontsize=16, fontweight='bold')\n",
    "        ax.set_title('MAE Variation Across Reynolds Numbers for Different Models\\n(Random Layout, 32 Sensors)', \n",
    "                     fontsize=18, fontweight='bold', pad=20)\n",
    "        \n",
    "        # Set x-axis to show all Reynolds numbers with log scale\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xticks(reynolds_numbers)\n",
    "        ax.set_xticklabels([str(re) for re in reynolds_numbers])\n",
    "        \n",
    "        # Add grid and legend\n",
    "        ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)\n",
    "        ax.legend(loc='best', fontsize=16, frameon=True, fancybox=True, shadow=True)\n",
    "        ax.tick_params(axis='both', labelsize=16)\n",
    "        \n",
    "        # Add bounding box\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(True)\n",
    "            spine.set_linewidth(0.5)\n",
    "            spine.set_color('black')\n",
    "        \n",
    "        # Add statistical annotations\n",
    "        # Find Reynolds number with highest and lowest average MAE across all models\n",
    "        all_reynolds_maes = []\n",
    "        for i in range(len(reynolds_numbers)):\n",
    "            re_maes = []\n",
    "            for data in mae_data.values():\n",
    "                if i < len(data['reynolds_maes']) and not np.isnan(data['reynolds_maes'][i]):\n",
    "                    re_maes.append(data['reynolds_maes'][i])\n",
    "            if re_maes:\n",
    "                all_reynolds_maes.append(np.mean(re_maes))\n",
    "            else:\n",
    "                all_reynolds_maes.append(np.nan)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('mae_across_reynolds_numbers_random_32.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.savefig('mae_across_reynolds_numbers_random_32.pdf', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.show()\n",
    "        \n",
    "        # Print summary statistics\n",
    "        print(\"Summary Statistics: MAE Across Reynolds Numbers\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"{'Model':<15} {'Min MAE':<10} {'Max MAE':<10} {'Range':<10} {'Avg MAE':<10}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        for model_type, data in mae_data.items():\n",
    "            model_label = data['model_label']\n",
    "            reynolds_maes = [mae for mae in data['reynolds_maes'] if not np.isnan(mae)]\n",
    "            \n",
    "            if reynolds_maes:\n",
    "                min_mae = np.min(reynolds_maes)\n",
    "                max_mae = np.max(reynolds_maes)\n",
    "                range_mae = max_mae - min_mae\n",
    "                avg_mae = np.mean(reynolds_maes)\n",
    "                \n",
    "                print(f\"{model_label:<15} {min_mae:<10.6f} {max_mae:<10.6f} {range_mae:<10.6f} {avg_mae:<10.6f}\")\n",
    "        \n",
    "        print(\"\\nReynolds Number-wise Average MAE (across all models):\")\n",
    "        print(\"-\" * 50)\n",
    "        for i, re_num in enumerate(reynolds_numbers):\n",
    "            re_maes = [data['reynolds_maes'][i] for data in mae_data.values() \n",
    "                      if i < len(data['reynolds_maes']) and not np.isnan(data['reynolds_maes'][i])]\n",
    "            if re_maes:\n",
    "                avg_re_mae = np.mean(re_maes)\n",
    "                print(f\"Re = {re_num:4d}: {avg_re_mae:.6f}\")\n",
    "        \n",
    "        print(\"\\nInterpretation:\")\n",
    "        print(\"- Higher MAE indicates more challenging reconstruction for that Reynolds number\")\n",
    "        print(\"- Generally higher Re flows are more complex and challenging to reconstruct\")\n",
    "        print(\"- Log scale on x-axis shows the wide range of Reynolds numbers tested\")\n",
    "        print(\"- Flat lines suggest consistent performance across Reynolds numbers\")\n",
    "        print(\"- Steep variations indicate Reynolds number-specific challenges\")\n",
    "        \n",
    "    else:\n",
    "        print(\"No random_32 data available for Reynolds number MAE analysis\")\n",
    "\n",
    "# Run the Reynolds number MAE line plot analysis\n",
    "plot_mae_across_channels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a217601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_noise_impact_on_error():\n",
    "    \"\"\"Analyze how reconstruction error changes with increasing noise levels\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import glob\n",
    "    import os\n",
    "    \n",
    "    print(\"Analyzing Noise Impact on Reconstruction Error\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Define noise levels to analyze\n",
    "    noise_levels = [0, 5, 10, 15, 20]  # 0 represents the normal file without noise\n",
    "    \n",
    "    # Model types and their filename patterns\n",
    "    model_patterns = {\n",
    "        'flrnet_fourier_percep': 'inference_random_32_standard',\n",
    "        'flrnet_fourier': 'inference_random_32_fourier', \n",
    "        'flrnet_percep': 'inference_random_32_no_fourier',\n",
    "        'flrnet_standard': 'inference_random_32_no_fourier_no_percep',\n",
    "        'mlp': 'mlp_random_32_standard',\n",
    "        'pod': 'pod_random_32_standard'\n",
    "    }\n",
    "    \n",
    "    model_labels = {\n",
    "        'flrnet_fourier_percep': 'FLRNet-FP',\n",
    "        'flrnet_fourier': 'FLRNet-F',\n",
    "        'flrnet_percep': 'FLRNet-P',\n",
    "        'flrnet_standard': 'FLRNet-Std',\n",
    "        'mlp': 'MLP',\n",
    "        'pod': 'POD'\n",
    "    }\n",
    "    \n",
    "    # Storage for results\n",
    "    noise_error_data = {}\n",
    "    \n",
    "    # Search for files in inference results directory\n",
    "    inference_dir = r\"E:\\Research\\Physics-informed-machine-learning\\flow_field_recon_parc\\checkpoints\\inference_results\"\n",
    "    \n",
    "    print(f\"Searching for noise files in: {inference_dir}\")\n",
    "    print()\n",
    "    \n",
    "    for model_type, base_pattern in model_patterns.items():\n",
    "        print(f\"Processing {model_labels[model_type]}...\")\n",
    "        \n",
    "        model_errors = []\n",
    "        found_files = []\n",
    "        \n",
    "        for noise_level in noise_levels:\n",
    "            error_value = None\n",
    "            file_found = False\n",
    "            \n",
    "            if noise_level == 0:\n",
    "                # Look for file without noise suffix\n",
    "                if model_type.startswith('flrnet'):\n",
    "                    search_pattern = f\"{base_pattern}.npz\"\n",
    "                else:\n",
    "                    search_pattern = f\"{base_pattern}.npz\"\n",
    "            else:\n",
    "                # Look for file with noise suffix\n",
    "                if model_type.startswith('flrnet'):\n",
    "                    search_pattern = f\"{base_pattern}_noise_{noise_level}pct.npz\"\n",
    "                else:\n",
    "                    search_pattern = f\"{base_pattern}_noise_{noise_level}pct.npz\"\n",
    "            \n",
    "            # Search for the file\n",
    "            full_pattern = os.path.join(inference_dir, search_pattern)\n",
    "            matching_files = glob.glob(full_pattern)\n",
    "            \n",
    "            if matching_files:\n",
    "                file_path = matching_files[0]\n",
    "                file_found = True\n",
    "                found_files.append(os.path.basename(file_path))\n",
    "                \n",
    "                try:\n",
    "                    # Load the file and calculate error\n",
    "                    data = np.load(file_path)\n",
    "                    \n",
    "                    if 'predictions' in data and 'targets' in data:\n",
    "                        predictions = data['predictions']\n",
    "                        targets = data['targets']\n",
    "                        \n",
    "                        # Ensure consistent shapes\n",
    "                        if len(predictions.shape) == 4 and predictions.shape[3] > predictions.shape[0]:\n",
    "                            predictions = np.transpose(predictions, (3, 1, 2, 0))\n",
    "                            targets = np.transpose(targets, (3, 1, 2, 0))\n",
    "                        \n",
    "                        # Calculate Mean Absolute Error across all data\n",
    "                        mae = np.mean(np.abs(targets - predictions))\n",
    "                        error_value = mae\n",
    "                        \n",
    "                        print(f\"  Noise {noise_level}%: MAE = {mae:.6f} (file: {os.path.basename(file_path)})\")\n",
    "                    else:\n",
    "                        print(f\"  Noise {noise_level}%: File missing predictions/targets\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"  Noise {noise_level}%: Error loading file - {e}\")\n",
    "            else:\n",
    "                print(f\"  Noise {noise_level}%: File not found (pattern: {search_pattern})\")\n",
    "            \n",
    "            model_errors.append(error_value)\n",
    "        \n",
    "        if any(error is not None for error in model_errors):\n",
    "            noise_error_data[model_type] = {\n",
    "                'label': model_labels[model_type],\n",
    "                'errors': model_errors,\n",
    "                'files': found_files\n",
    "            }\n",
    "            print(f\"  ✓ {model_labels[model_type]}: {sum(1 for e in model_errors if e is not None)}/{len(noise_levels)} files found\")\n",
    "        else:\n",
    "            print(f\"  ✗ {model_labels[model_type]}: No valid files found\")\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    # Create the noise impact plot\n",
    "    if noise_error_data:\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        # Enhanced styling\n",
    "        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "        markers = ['o', 's', '^', 'D', 'v', 'p']\n",
    "        linestyles = ['-', '-', '-', '-', '-', '-']\n",
    "        \n",
    "        # Plot data for each model\n",
    "        for i, (model_type, data) in enumerate(noise_error_data.items()):\n",
    "            model_label = data['label']\n",
    "            errors = data['errors']\n",
    "            \n",
    "            # Filter out None values and corresponding noise levels\n",
    "            valid_noise_levels = []\n",
    "            valid_errors = []\n",
    "            \n",
    "            for noise_level, error in zip(noise_levels, errors):\n",
    "                if error is not None:\n",
    "                    valid_noise_levels.append(noise_level)\n",
    "                    valid_errors.append(error)\n",
    "            \n",
    "            if valid_errors:\n",
    "                ax.plot(valid_noise_levels, valid_errors,\n",
    "                       label=model_label,\n",
    "                       color=colors[i % len(colors)],\n",
    "                       marker=markers[i % len(markers)],\n",
    "                       markersize=8,\n",
    "                       linewidth=3,\n",
    "                       markerfacecolor='white',\n",
    "                       markeredgewidth=2,\n",
    "                       markeredgecolor=colors[i % len(colors)],\n",
    "                       linestyle=linestyles[i % len(linestyles)],\n",
    "                       alpha=0.9)\n",
    "        \n",
    "        # Styling\n",
    "        ax.set_xlabel('Noise Level (%)', fontsize=16, fontweight='bold')\n",
    "        ax.set_ylabel('Mean Absolute Error [m/s]', fontsize=16, fontweight='bold')\n",
    "        ax.set_title('Impact of Noise Perturbation in Sensor Measurement on Reconstruction Error', \n",
    "                     fontsize=18, fontweight='bold', pad=20)\n",
    "        \n",
    "        # Set x-axis to show all noise levels\n",
    "        ax.set_xticks(noise_levels)\n",
    "        ax.set_xticklabels([f'{level}%' for level in noise_levels])\n",
    "        \n",
    "        # Add grid and legend\n",
    "        ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)\n",
    "        ax.legend(loc='best', fontsize=14, frameon=True, fancybox=True, shadow=True)\n",
    "        ax.tick_params(axis='both', labelsize=14)\n",
    "        \n",
    "        # Add bounding box\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(True)\n",
    "            spine.set_linewidth(0.5)\n",
    "            spine.set_color('black')\n",
    "        \n",
    "        # Set y-axis to start from 0\n",
    "        ax.set_ylim(bottom=0)\n",
    "\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('noise_impact_on_reconstruction_error.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.savefig('noise_impact_on_reconstruction_error.pdf', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.show()\n",
    "        \n",
    "        # Print summary statistics\n",
    "        print(\"Summary Statistics: Noise Impact Analysis\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"{'Model':<15} {'0% MAE':<12} {'20% MAE':<12} {'Increase':<12} {'% Change':<12}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        for model_type, data in noise_error_data.items():\n",
    "            model_label = data['label']\n",
    "            errors = data['errors']\n",
    "            \n",
    "            # Get 0% and 20% noise errors if available\n",
    "            mae_0 = errors[0] if errors[0] is not None else np.nan\n",
    "            mae_20 = errors[4] if len(errors) > 4 and errors[4] is not None else np.nan\n",
    "            \n",
    "            if not np.isnan(mae_0) and not np.isnan(mae_20):\n",
    "                increase = mae_20 - mae_0\n",
    "                percent_change = (increase / mae_0) * 100\n",
    "                \n",
    "                print(f\"{model_label:<15} {mae_0:<12.6f} {mae_20:<12.6f} {increase:<12.6f} {percent_change:<12.2f}\")\n",
    "        \n",
    "        print(f\"\\nNoise Level Analysis:\")\n",
    "        print(\"-\" * 50)\n",
    "        for i, noise_level in enumerate(noise_levels):\n",
    "            level_errors = []\n",
    "            for data in noise_error_data.values():\n",
    "                if i < len(data['errors']) and data['errors'][i] is not None:\n",
    "                    level_errors.append(data['errors'][i])\n",
    "            \n",
    "            if level_errors:\n",
    "                avg_error = np.mean(level_errors)\n",
    "                std_error = np.std(level_errors)\n",
    "                print(f\"Noise {noise_level:2d}%: Avg MAE = {avg_error:.6f} ± {std_error:.6f} ({len(level_errors)} models)\")\n",
    "        \n",
    "        print(f\"\\nInterpretation:\")\n",
    "        print(\"- Higher noise levels generally increase reconstruction error\")\n",
    "        print(\"- Some models may be more robust to noise than others\")\n",
    "        print(\"- The slope of each line indicates noise sensitivity\")\n",
    "        print(\"- Steeper slopes indicate higher noise sensitivity\")\n",
    "        print(\"- Models with flatter curves are more noise-resistant\")\n",
    "        \n",
    "        return noise_error_data\n",
    "    else:\n",
    "        print(\"No valid noise data files found for analysis\")\n",
    "        return None\n",
    "\n",
    "# Run the noise impact analysis\n",
    "noise_analysis_results = analyze_noise_impact_on_error()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
