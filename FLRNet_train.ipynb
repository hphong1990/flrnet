{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from keras.layers import *\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_unit(feat_dim, kernel_size, x_in, padding=\"CONSTANT\"):\n",
    "    \"\"\"\n",
    "    Conv unit: x_in --> Conv k x k + relu --> Conv 1 x 1 + relu --> output\n",
    "    Parameter: \n",
    "                - x_in (tensor): input tensor\n",
    "                - feat_dim (int): number of channels\n",
    "                - kernel_size (k) (int): size of convolution kernel\n",
    "                - padding (str): padding method to use\n",
    "    Return:\n",
    "                - (tensor): output of the conv unit\n",
    "    \"\"\"\n",
    "    x = Conv2D(feat_dim, kernel_size, activation=LeakyReLU(0.2), padding=\"same\")(x_in)\n",
    "    x = Conv2D(feat_dim, 1, activation=LeakyReLU(0.2), padding=\"same\")(x)\n",
    "    return x\n",
    "\n",
    "def conv_block_down(x, feat_dim, reps, kernel_size, mode='normal', padding=\"CONSTANT\"):\n",
    "    if mode == 'down':\n",
    "        x = MaxPooling2D(2,2)(x)\n",
    "    for _ in range(reps):\n",
    "        x = conv_unit(feat_dim, kernel_size, x, padding)\n",
    "    return x\n",
    "\n",
    "def conv_block_up_w_concat(x, x1, feat_dim, reps, kernel_size, mode='normal', padding=\"CONSTANT\"):\n",
    "    if mode == 'up':\n",
    "        x = UpSampling2D((2,2),interpolation='bilinear')(x)\n",
    "    x = Concatenate()([x,x1])\n",
    "    for _ in range(reps):\n",
    "        x = conv_unit(feat_dim, kernel_size, x, padding)\n",
    "    return x\n",
    "\n",
    "def conv_block_up_wo_concat(x, feat_dim, reps, kernel_size, mode='normal', padding=\"CONSTANT\"):\n",
    "    if mode == 'up':\n",
    "        x = UpSampling2D((2,2),interpolation='bilinear')(x)\n",
    "    for _ in range(reps):\n",
    "        x = conv_unit(feat_dim, kernel_size, x, padding)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "\n",
    "        epsilon = tf.random.normal(shape=tf.shape(z_mean))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 64, 128, 1)   0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 64, 128, 64)  640         ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 64, 128, 64)  4160        ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 32, 64, 64)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 32, 64, 128)  73856       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 32, 64, 128)  16512       ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 16, 32, 128)  0          ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 16, 32, 128)  147584      ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 16, 32, 128)  16512       ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 16, 32, 128)  147584      ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 16, 32, 128)  16512       ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 8, 16, 128)  0           ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 8, 16, 256)   295168      ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 8, 16, 256)   65792       ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 8, 16, 256)   590080      ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 8, 16, 256)   65792       ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 4, 8, 256)   0           ['conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 4, 8, 256)    590080      ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 4, 8, 256)    65792       ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 4, 8, 256)    590080      ['conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 4, 8, 256)    65792       ['conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " z_mean (Conv2D)                (None, 4, 8, 4)      9220        ['conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " z_log_var (Conv2D)             (None, 4, 8, 4)      9220        ['conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " sampling (Sampling)            (None, 4, 8, 4)      0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,770,376\n",
      "Trainable params: 2,770,376\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Encoder\n",
    "def vgg_encoder(latent_dims = 4, input_shape = (128,256,1), n_base_features = 64):\n",
    "    inputs = keras.Input(shape = input_shape)\n",
    "    conv1 = conv_block_down(inputs,\n",
    "                            feat_dim = n_base_features,\n",
    "                            reps = 1,\n",
    "                            kernel_size = 3,\n",
    "                            mode = 'down')\n",
    "    conv2 = conv_block_down(conv1,\n",
    "                            feat_dim = n_base_features*2,\n",
    "                            reps = 1,\n",
    "                            kernel_size = 3,\n",
    "                            mode = 'down')\n",
    "    conv3 = conv_block_down(conv2,\n",
    "                            feat_dim = n_base_features*2,\n",
    "                            reps = 2,\n",
    "                            kernel_size = 3,\n",
    "                            mode = 'down')\n",
    "    conv4 = conv_block_down(conv3,\n",
    "                            feat_dim = n_base_features*4,\n",
    "                            reps = 2,\n",
    "                            kernel_size = 3,\n",
    "                            mode = 'down')\n",
    "    conv5 = conv_block_down(conv4,\n",
    "                            feat_dim = n_base_features*4,\n",
    "                            reps = 2,\n",
    "                            kernel_size = 3,\n",
    "                            mode = 'down')   \n",
    "    \n",
    "    z_mean = layers.Conv2D(latent_dims,3, padding=\"same\",name=\"z_mean\")(conv5)\n",
    "    z_log_var = layers.Conv2D(latent_dims,3, padding=\"same\",name=\"z_log_var\")(conv5)\n",
    "    z = Sampling()([z_mean,z_log_var])\n",
    "    encoder = keras.Model(inputs, [z_mean,z_log_var,z])\n",
    "    return encoder\n",
    "vgg_encoder().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 4, 8, 4)]         0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 4, 8, 256)         9472      \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 8, 16, 256)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 8, 16, 256)        590080    \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 8, 16, 256)        65792     \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 8, 16, 256)        590080    \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 8, 16, 256)        65792     \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 16, 32, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 16, 32, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 16, 32, 256)       65792     \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 16, 32, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 16, 32, 256)       65792     \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSampling  (None, 32, 64, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 32, 64, 128)       295040    \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 32, 64, 128)       16512     \n",
      "                                                                 \n",
      " up_sampling2d_3 (UpSampling  (None, 64, 128, 128)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 64, 128, 128)      147584    \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 64, 128, 128)      16512     \n",
      "                                                                 \n",
      " up_sampling2d_4 (UpSampling  (None, 128, 256, 128)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 128, 256, 64)      73792     \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 128, 256, 64)      4160      \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 128, 256, 1)       577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,187,137\n",
      "Trainable params: 3,187,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Decoder\n",
    "def vgg_decoder(input_shape = (4,8,4), n_base_features = 64):\n",
    "    inputs = keras.Input(shape = input_shape)\n",
    "    conv_in = layers.Conv2D(n_base_features*4, 3, activation = LeakyReLU(0.2), padding=\"same\")(inputs)\n",
    "\n",
    "    conv1 = conv_block_up_wo_concat(conv_in,\n",
    "                            feat_dim = n_base_features*4,\n",
    "                            reps = 2,\n",
    "                            kernel_size = 3,\n",
    "                            mode = 'up')\n",
    "    conv2 = conv_block_up_wo_concat(conv1,\n",
    "                            feat_dim = n_base_features*4,\n",
    "                            reps = 2,\n",
    "                            kernel_size = 3,\n",
    "                            mode = 'up')\n",
    "    conv3 = conv_block_up_wo_concat(conv2,\n",
    "                            feat_dim = n_base_features*2,\n",
    "                            reps = 1,\n",
    "                            kernel_size = 3,\n",
    "                            mode = 'up')\n",
    "    conv4 = conv_block_up_wo_concat(conv3,\n",
    "                            feat_dim = n_base_features*2,\n",
    "                            reps = 1,\n",
    "                            kernel_size = 3,\n",
    "                            mode = 'up')\n",
    "    conv5 = conv_block_up_wo_concat(conv4,\n",
    "                            feat_dim = n_base_features,\n",
    "                            reps = 1,\n",
    "                            kernel_size = 3,\n",
    "                            mode = 'up')\n",
    "    conv_out = layers.Conv2D(1, 3, padding=\"same\")(conv5)\n",
    "    decoder = keras.Model(inputs, conv_out)\n",
    "    return decoder\n",
    "vgg_decoder().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensor - Latent var mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network\n",
    "no_of_sensor = 8\n",
    "\n",
    "def create_mapping_operator(no_of_sensor = 8, latent_dim = (4,8,4)):\n",
    "    inputs = keras.Input(shape = (no_of_sensor))\n",
    "    fc_1 = Dense(128, activation=LeakyReLU(0.2))(inputs)\n",
    "    fc_2 = Dense(256, activation=LeakyReLU(0.2))(fc_1)\n",
    "    fc_3 = Dense(512, activation=LeakyReLU(0.2))(fc_2)\n",
    "    fc_3 = Dense(256, activation=LeakyReLU(0.2))(fc_2)\n",
    "    fc_4 = Dense(128)(fc_3)\n",
    "    latent_var = Reshape(target_shape=latent_dim)(fc_4)\n",
    "    z_mean = layers.Conv2D(latent_dim[2],3, padding=\"same\",name=\"z_mean\")(latent_var)\n",
    "    z_log_var = layers.Conv2D(latent_dim[2],3, padding=\"same\",name=\"z_log_var\")(latent_var)\n",
    "    z = Sampling()([z_mean,z_log_var])\n",
    "    mapping = keras.Model(inputs, [z_mean,z_log_var,z])\n",
    "    return mapping\n",
    "# create_mapping_operator().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer class\n",
    "class FLRNet(keras.Model):\n",
    "    def __init__(self,  n_sensor = 8, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = vgg_encoder()\n",
    "        self.decoder = vgg_decoder()\n",
    "        self.sens_mapping = create_mapping_operator(no_of_sensor=n_sensor)\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss_ae\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss_ae\")\n",
    "        self.sens_reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss_sens\"\n",
    "        )\n",
    "        self.sens_kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss_sens\")\n",
    "        \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "            self.sens_reconstruction_loss_tracker,\n",
    "            self.sens_kl_loss_tracker,\n",
    "        ]\n",
    "    def kld(self, mean_1, mean_2, z_log_var_1, z_log_var_2):\n",
    "        var_1 = tf.exp(z_log_var_1)\n",
    "        var_2 = tf.exp(z_log_var_2)\n",
    "        kl_loss = ( \n",
    "            tf.math.log((var_2 / var_1) ** 0.5) \n",
    "              + (var_1 + (mean_1 - mean_2) ** 2) / (2 * var_2) \n",
    "              - 0.5\n",
    "           )\n",
    "        return kl_loss\n",
    "    # def perceptual_loss(self, y_pred, gt):\n",
    "    #     # Pred perceptaul\n",
    "    #     pred_feature = self.vgg19(y_pred)\n",
    "    #     # GT perceptual\n",
    "    #     gt_feature = self.vgg19(gt)\n",
    "    #     return tf.keras.losses.MeanSquaredError(reduction = 'sum')(pred_feature,gt_feature)\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        sens_inp = tf.cast(data[0], dtype = tf.float32)\n",
    "        img_inp = tf.cast(data[1],dtype = tf.float32)\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Autoencoder\n",
    "            z_mean_ae, z_log_var_ae, z_ae = self.encoder(img_inp)\n",
    "            reconstruction_ae = self.decoder(z_ae)\n",
    "            reconstruction_loss_ae = tf.keras.losses.MeanAbsoluteError(reduction = 'sum')(reconstruction_ae,img_inp)\n",
    "            \n",
    "            kl_loss_ae = -0.5 * (1 + z_log_var_ae - tf.square(z_mean_ae) - tf.exp(z_log_var_ae))\n",
    "            kl_loss_ae = (tf.reduce_sum(kl_loss_ae, axis=(1,2,3)))\n",
    "\n",
    "            # Sens recon\n",
    "            z_mean_sens, z_log_var_sens, z_sens = self.sens_mapping(sens_inp)\n",
    "            reconstruction_sens = self.decoder(z_sens)\n",
    "            reconstruction_loss_sens = tf.keras.losses.MeanAbsoluteError(reduction = 'sum')(reconstruction_sens,img_inp)\n",
    "            \n",
    "            kl_loss_sens = self.kld(z_mean_sens,z_mean_ae,z_log_var_sens, z_log_var_ae)\n",
    "            kl_loss_sens = (tf.reduce_sum(kl_loss_sens, axis=(1,2,3)))\n",
    "\n",
    "            # perceptual_loss = self.perceptual_loss(reconstruction,data)\n",
    "            total_loss = reconstruction_loss_ae + kl_loss_ae + reconstruction_loss_sens + kl_loss_sens\n",
    "            \n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss_ae)\n",
    "        self.kl_loss_tracker.update_state(kl_loss_ae)\n",
    "        self.sens_reconstruction_loss_tracker.update_state(reconstruction_loss_sens)\n",
    "        self.sens_kl_loss_tracker.update_state(kl_loss_sens)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss_ae\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss_ae\": self.kl_loss_tracker.result(),\n",
    "            \"reconstruction_loss_sens\": self.sens_reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss_sens\": self.sens_kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(429, 8)\n",
      "(429, 128, 256, 1)\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 128, 256, 1), dtype=tf.float64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# Prepare field data\n",
    "no_of_sensor = 8\n",
    "\n",
    "Re_list_train = [300, 400, 450, 500, 600, 650, 700, 800, 850, 900, 1000]\n",
    "Re_list_test = [350, 550, 750, 950]\n",
    "\n",
    "sensor_data_whole = []\n",
    "full_field_data_whole = []\n",
    "for Re in Re_list_train:\n",
    "    filename = \"D:/data/flow_field_recon/random_sensor_data/sensor_data_\" + str(no_of_sensor) + \"_\" + str(Re) + \".npy\"\n",
    "    sensor_data = np.load(filename)\n",
    "    sensor_data_whole.append(sensor_data)\n",
    "    filename_field = \"D:/data/flow_field_recon/full_field_data/full_field_data_\" + str(Re) + \".npy\"\n",
    "    full_field_data_whole.append(np.load(filename_field))\n",
    "\n",
    "sensor_data_whole_array = np.swapaxes(np.concatenate(sensor_data_whole,axis = -1), 0,1)\n",
    "full_field_data_whole_array = np.swapaxes(\n",
    "    np.expand_dims(\n",
    "        np.concatenate(full_field_data_whole, axis = -1), axis = 0),\n",
    "        0, -1)\n",
    "\n",
    "print(sensor_data_whole_array.shape)\n",
    "print(full_field_data_whole_array.shape)\n",
    "\n",
    "# Create tf.dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((sensor_data_whole_array,full_field_data_whole_array))\n",
    "dataset = dataset.shuffle(buffer_size = 2192) \n",
    "dataset = dataset.batch(8)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare sensor data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "54/54 [==============================] - 231s 4s/step - loss: 397030.4301 - reconstruction_loss_ae: 144707.2031 - kl_loss_ae: 0.0534 - reconstruction_loss_sens: 144314.9531 - kl_loss_sens: 1.5559\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 239s 4s/step - loss: 176425.3105 - reconstruction_loss_ae: 81108.9922 - kl_loss_ae: 0.0202 - reconstruction_loss_sens: 80840.3125 - kl_loss_sens: 1.6213\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 241s 4s/step - loss: 140944.7131 - reconstruction_loss_ae: 69414.7578 - kl_loss_ae: 0.1033 - reconstruction_loss_sens: 69276.4453 - kl_loss_sens: 1.9028\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 242s 4s/step - loss: 137749.6213 - reconstruction_loss_ae: 67252.4297 - kl_loss_ae: 0.3797 - reconstruction_loss_sens: 66521.5156 - kl_loss_sens: 2.8297\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 244s 5s/step - loss: 128188.3626 - reconstruction_loss_ae: 64289.2969 - kl_loss_ae: 2.0819 - reconstruction_loss_sens: 63873.1523 - kl_loss_sens: 5.7524\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 244s 5s/step - loss: 125256.5547 - reconstruction_loss_ae: 62406.8828 - kl_loss_ae: 4.0706 - reconstruction_loss_sens: 61943.0039 - kl_loss_sens: 8.7592\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 245s 5s/step - loss: 120964.5601 - reconstruction_loss_ae: 57662.3516 - kl_loss_ae: 22.8893 - reconstruction_loss_sens: 59189.2461 - kl_loss_sens: 40.0968\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 250s 5s/step - loss: 106589.6099 - reconstruction_loss_ae: 46019.6758 - kl_loss_ae: 99.1557 - reconstruction_loss_sens: 55772.8828 - kl_loss_sens: 464.7834\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 262s 5s/step - loss: 95367.8920 - reconstruction_loss_ae: 37004.4883 - kl_loss_ae: 145.8082 - reconstruction_loss_sens: 53480.6211 - kl_loss_sens: 721.8842\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 288s 5s/step - loss: 84674.9490 - reconstruction_loss_ae: 31045.8145 - kl_loss_ae: 180.6881 - reconstruction_loss_sens: 51005.4766 - kl_loss_sens: 814.6723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1668c871508>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "flow_recon_net = FLRNet()\n",
    "flow_recon_net.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00005, beta_1 = 0.9, beta_2 = 0.999))\n",
    "flow_recon_net.fit(dataset, epochs = 10, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
