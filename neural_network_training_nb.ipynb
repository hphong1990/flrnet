{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from keras.layers import *\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_unit(feat_dim, kernel_size, x_in, padding=\"CONSTANT\"):\n",
    "    \"\"\"\n",
    "    Conv unit: x_in --> Conv k x k + relu --> Conv 1 x 1 + relu --> output\n",
    "    Parameter: \n",
    "                - x_in (tensor): input tensor\n",
    "                - feat_dim (int): number of channels\n",
    "                - kernel_size (k) (int): size of convolution kernel\n",
    "                - padding (str): padding method to use\n",
    "    Return:\n",
    "                - (tensor): output of the conv unit\n",
    "    \"\"\"\n",
    "    x = Conv2D(feat_dim, kernel_size, activation=LeakyReLU(0.2), padding=\"same\")(x_in)\n",
    "    x = Conv2D(feat_dim, 1, activation=LeakyReLU(0.2), padding=\"same\")(x)\n",
    "    return x\n",
    "\n",
    "def conv_block_down(x, feat_dim, reps, kernel_size, mode='normal', padding=\"CONSTANT\"):\n",
    "    if mode == 'down':\n",
    "        x = MaxPooling2D(2,2)(x)\n",
    "    for _ in range(reps):\n",
    "        x = conv_unit(feat_dim, kernel_size, x, padding)\n",
    "    return x\n",
    "\n",
    "def conv_block_up_w_concat(x, x1, feat_dim, reps, kernel_size, mode='normal', padding=\"CONSTANT\"):\n",
    "    if mode == 'up':\n",
    "        x = UpSampling2D((2,2),interpolation='bilinear')(x)\n",
    "    x = Concatenate()([x,x1])\n",
    "    for _ in range(reps):\n",
    "        x = conv_unit(feat_dim, kernel_size, x, padding)\n",
    "    return x\n",
    "\n",
    "def conv_block_up_wo_concat(x, feat_dim, reps, kernel_size, mode='normal', padding=\"CONSTANT\"):\n",
    "    if mode == 'up':\n",
    "        x = UpSampling2D((2,2),interpolation='bilinear')(x)\n",
    "    for _ in range(reps):\n",
    "        x = conv_unit(feat_dim, kernel_size, x, padding)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "\n",
    "        epsilon = tf.random.normal(shape=tf.shape(z_mean))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)          [(None, 128, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_27 (MaxPooling2D  (None, 64, 128, 1)  0           ['input_13[0][0]']               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_97 (Conv2D)             (None, 64, 128, 64)  640         ['max_pooling2d_27[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_98 (Conv2D)             (None, 64, 128, 64)  4160        ['conv2d_97[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_28 (MaxPooling2D  (None, 32, 64, 64)  0           ['conv2d_98[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_99 (Conv2D)             (None, 32, 64, 128)  73856       ['max_pooling2d_28[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_100 (Conv2D)            (None, 32, 64, 128)  16512       ['conv2d_99[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_29 (MaxPooling2D  (None, 16, 32, 128)  0          ['conv2d_100[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_101 (Conv2D)            (None, 16, 32, 128)  147584      ['max_pooling2d_29[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_102 (Conv2D)            (None, 16, 32, 128)  16512       ['conv2d_101[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_103 (Conv2D)            (None, 16, 32, 128)  147584      ['conv2d_102[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_104 (Conv2D)            (None, 16, 32, 128)  16512       ['conv2d_103[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_30 (MaxPooling2D  (None, 8, 16, 128)  0           ['conv2d_104[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_105 (Conv2D)            (None, 8, 16, 256)   295168      ['max_pooling2d_30[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_106 (Conv2D)            (None, 8, 16, 256)   65792       ['conv2d_105[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_107 (Conv2D)            (None, 8, 16, 256)   590080      ['conv2d_106[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_108 (Conv2D)            (None, 8, 16, 256)   65792       ['conv2d_107[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_31 (MaxPooling2D  (None, 4, 8, 256)   0           ['conv2d_108[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_109 (Conv2D)            (None, 4, 8, 256)    590080      ['max_pooling2d_31[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_110 (Conv2D)            (None, 4, 8, 256)    65792       ['conv2d_109[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_111 (Conv2D)            (None, 4, 8, 256)    590080      ['conv2d_110[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_112 (Conv2D)            (None, 4, 8, 256)    65792       ['conv2d_111[0][0]']             \n",
      "                                                                                                  \n",
      " z_mean (Conv2D)                (None, 4, 8, 4)      9220        ['conv2d_112[0][0]']             \n",
      "                                                                                                  \n",
      " z_log_var (Conv2D)             (None, 4, 8, 4)      9220        ['conv2d_112[0][0]']             \n",
      "                                                                                                  \n",
      " sampling_6 (Sampling)          (None, 4, 8, 4)      0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,770,376\n",
      "Trainable params: 2,770,376\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Encoder\n",
    "def vgg_encoder(latent_dims = 4, input_shape = (128,256,1), n_base_features = 64):\n",
    "    inputs = keras.Input(shape = input_shape)\n",
    "    conv1 = conv_block_down(inputs,\n",
    "                            feat_dim = n_base_features,\n",
    "                            reps = 1,\n",
    "                            kernel_size = 3,\n",
    "                            mode = 'down')\n",
    "    conv2 = conv_block_down(conv1,\n",
    "                            feat_dim = n_base_features*2,\n",
    "                            reps = 1,\n",
    "                            kernel_size = 3,\n",
    "                            mode = 'down')\n",
    "    conv3 = conv_block_down(conv2,\n",
    "                            feat_dim = n_base_features*2,\n",
    "                            reps = 2,\n",
    "                            kernel_size = 3,\n",
    "                            mode = 'down')\n",
    "    conv4 = conv_block_down(conv3,\n",
    "                            feat_dim = n_base_features*4,\n",
    "                            reps = 2,\n",
    "                            kernel_size = 3,\n",
    "                            mode = 'down')\n",
    "    conv5 = conv_block_down(conv4,\n",
    "                            feat_dim = n_base_features*4,\n",
    "                            reps = 2,\n",
    "                            kernel_size = 3,\n",
    "                            mode = 'down')   \n",
    "    \n",
    "    z_mean = layers.Conv2D(latent_dims,3, padding=\"same\",name=\"z_mean\")(conv5)\n",
    "    z_log_var = layers.Conv2D(latent_dims,3, padding=\"same\",name=\"z_log_var\")(conv5)\n",
    "    z = Sampling()([z_mean,z_log_var])\n",
    "    encoder = keras.Model(inputs, [z_mean,z_log_var,z])\n",
    "    return encoder\n",
    "vgg_encoder().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_17 (InputLayer)       [(None, 4, 8, 4)]         0         \n",
      "                                                                 \n",
      " conv2d_161 (Conv2D)         (None, 4, 8, 256)         9472      \n",
      "                                                                 \n",
      " up_sampling2d_12 (UpSamplin  (None, 8, 16, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_162 (Conv2D)         (None, 8, 16, 256)        590080    \n",
      "                                                                 \n",
      " conv2d_163 (Conv2D)         (None, 8, 16, 256)        65792     \n",
      "                                                                 \n",
      " conv2d_164 (Conv2D)         (None, 8, 16, 256)        590080    \n",
      "                                                                 \n",
      " conv2d_165 (Conv2D)         (None, 8, 16, 256)        65792     \n",
      "                                                                 \n",
      " up_sampling2d_13 (UpSamplin  (None, 16, 32, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_166 (Conv2D)         (None, 16, 32, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_167 (Conv2D)         (None, 16, 32, 256)       65792     \n",
      "                                                                 \n",
      " conv2d_168 (Conv2D)         (None, 16, 32, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_169 (Conv2D)         (None, 16, 32, 256)       65792     \n",
      "                                                                 \n",
      " up_sampling2d_14 (UpSamplin  (None, 32, 64, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_170 (Conv2D)         (None, 32, 64, 128)       295040    \n",
      "                                                                 \n",
      " conv2d_171 (Conv2D)         (None, 32, 64, 128)       16512     \n",
      "                                                                 \n",
      " up_sampling2d_15 (UpSamplin  (None, 64, 128, 128)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_172 (Conv2D)         (None, 64, 128, 128)      147584    \n",
      "                                                                 \n",
      " conv2d_173 (Conv2D)         (None, 64, 128, 128)      16512     \n",
      "                                                                 \n",
      " up_sampling2d_16 (UpSamplin  (None, 128, 256, 128)    0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_174 (Conv2D)         (None, 128, 256, 64)      73792     \n",
      "                                                                 \n",
      " conv2d_175 (Conv2D)         (None, 128, 256, 64)      4160      \n",
      "                                                                 \n",
      " conv2d_176 (Conv2D)         (None, 128, 256, 1)       577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,187,137\n",
      "Trainable params: 3,187,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Decoder\n",
    "def vgg_decoder(input_shape = (4,8,4), n_base_features = 64):\n",
    "    inputs = keras.Input(shape = input_shape)\n",
    "    conv_in = layers.Conv2D(n_base_features*4, 3, activation = LeakyReLU(0.2), padding=\"same\")(inputs)\n",
    "\n",
    "    conv1 = conv_block_up_wo_concat(conv_in,\n",
    "                            feat_dim = n_base_features*4,\n",
    "                            reps = 2,\n",
    "                            kernel_size = 3,\n",
    "                            mode = 'up')\n",
    "    conv2 = conv_block_up_wo_concat(conv1,\n",
    "                            feat_dim = n_base_features*4,\n",
    "                            reps = 2,\n",
    "                            kernel_size = 3,\n",
    "                            mode = 'up')\n",
    "    conv3 = conv_block_up_wo_concat(conv2,\n",
    "                            feat_dim = n_base_features*2,\n",
    "                            reps = 1,\n",
    "                            kernel_size = 3,\n",
    "                            mode = 'up')\n",
    "    conv4 = conv_block_up_wo_concat(conv3,\n",
    "                            feat_dim = n_base_features*2,\n",
    "                            reps = 1,\n",
    "                            kernel_size = 3,\n",
    "                            mode = 'up')\n",
    "    conv5 = conv_block_up_wo_concat(conv4,\n",
    "                            feat_dim = n_base_features,\n",
    "                            reps = 1,\n",
    "                            kernel_size = 3,\n",
    "                            mode = 'up')\n",
    "    conv_out = layers.Conv2D(1, 3, padding=\"same\")(conv5)\n",
    "    decoder = keras.Model(inputs, conv_out)\n",
    "    return decoder\n",
    "vgg_decoder().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensor - Latent var mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_19 (InputLayer)          [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 128)          1152        ['input_19[0][0]']               \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 256)          33024       ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 256)          65792       ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 128)          32896       ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 4, 8, 4)      0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " z_mean (Conv2D)                (None, 4, 8, 4)      148         ['reshape_3[0][0]']              \n",
      "                                                                                                  \n",
      " z_log_var (Conv2D)             (None, 4, 8, 4)      148         ['reshape_3[0][0]']              \n",
      "                                                                                                  \n",
      " sampling_7 (Sampling)          (None, 4, 8, 4)      0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 133,160\n",
      "Trainable params: 133,160\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Neural network\n",
    "no_of_sensor = 8\n",
    "\n",
    "def create_mapping_operator(no_of_sensor = 8, latent_dim = (4,8,4)):\n",
    "    inputs = keras.Input(shape = (no_of_sensor))\n",
    "    fc_1 = Dense(128, activation=LeakyReLU(0.2))(inputs)\n",
    "    fc_2 = Dense(256, activation=LeakyReLU(0.2))(fc_1)\n",
    "    fc_3 = Dense(512, activation=LeakyReLU(0.2))(fc_2)\n",
    "    fc_3 = Dense(256, activation=LeakyReLU(0.2))(fc_2)\n",
    "    fc_4 = Dense(128)(fc_3)\n",
    "    latent_var = Reshape(target_shape=latent_dim)(fc_4)\n",
    "    z_mean = layers.Conv2D(latent_dim[2],3, padding=\"same\",name=\"z_mean\")(latent_var)\n",
    "    z_log_var = layers.Conv2D(latent_dim[2],3, padding=\"same\",name=\"z_log_var\")(latent_var)\n",
    "    z = Sampling()([z_mean,z_log_var])\n",
    "    mapping = keras.Model(inputs, [z_mean,z_log_var,z])\n",
    "    return mapping\n",
    "# create_mapping_operator().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer class\n",
    "class FLRNet(keras.Model):\n",
    "    def __init__(self,  n_sensor = 8, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = vgg_encoder()\n",
    "        self.decoder = vgg_decoder()\n",
    "        self.sens_mapping = create_mapping_operator(no_of_sensor=n_sensor)\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss_ae\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss_ae\")\n",
    "        self.sens_reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss_sens\"\n",
    "        )\n",
    "        self.sens_kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss_sens\")\n",
    "        \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "            self.sens_reconstruction_loss_tracker,\n",
    "            self.sens_kl_loss_tracker,\n",
    "        ]\n",
    "    def kld(self, mean_1, mean_2, z_log_var_1, z_log_var_2):\n",
    "        var_1 = tf.exp(z_log_var_1)\n",
    "        var_2 = tf.exp(z_log_var_2)\n",
    "        kl_loss = ( \n",
    "            tf.math.log((var_2 / var_1) ** 0.5) \n",
    "              + (var_1 + (mean_1 - mean_2) ** 2) / (2 * var_2) \n",
    "              - 0.5\n",
    "           )\n",
    "        return kl_loss\n",
    "    # def perceptual_loss(self, y_pred, gt):\n",
    "    #     # Pred perceptaul\n",
    "    #     pred_feature = self.vgg19(y_pred)\n",
    "    #     # GT perceptual\n",
    "    #     gt_feature = self.vgg19(gt)\n",
    "    #     return tf.keras.losses.MeanSquaredError(reduction = 'sum')(pred_feature,gt_feature)\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        sens_inp = tf.cast(data[0], dtype = tf.float32)\n",
    "        img_inp = tf.cast(data[1],dtype = tf.float32)\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Autoencoder\n",
    "            z_mean_ae, z_log_var_ae, z_ae = self.encoder(img_inp)\n",
    "            reconstruction_ae = self.decoder(z_ae)\n",
    "            reconstruction_loss_ae = tf.keras.losses.MeanAbsoluteError(reduction = 'sum')(reconstruction_ae,img_inp)\n",
    "            \n",
    "            kl_loss_ae = -0.5 * (1 + z_log_var_ae - tf.square(z_mean_ae) - tf.exp(z_log_var_ae))\n",
    "            kl_loss_ae = (tf.reduce_sum(kl_loss_ae, axis=(1,2,3)))\n",
    "\n",
    "            # Sens recon\n",
    "            z_mean_sens, z_log_var_sens, z_sens = self.sens_mapping(sens_inp)\n",
    "            reconstruction_sens = self.decoder(z_sens)\n",
    "            reconstruction_loss_sens = tf.keras.losses.MeanAbsoluteError(reduction = 'sum')(reconstruction_sens,img_inp)\n",
    "            \n",
    "            kl_loss_sens = self.kld(z_mean_sens,z_mean_ae,z_log_var_sens, z_log_var_ae)\n",
    "            kl_loss_sens = (tf.reduce_sum(kl_loss_sens, axis=(1,2,3)))\n",
    "\n",
    "            # perceptual_loss = self.perceptual_loss(reconstruction,data)\n",
    "            total_loss = reconstruction_loss_ae + kl_loss_ae + reconstruction_loss_sens + kl_loss_sens\n",
    "            \n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss_ae)\n",
    "        self.kl_loss_tracker.update_state(kl_loss_ae)\n",
    "        self.sens_reconstruction_loss_tracker.update_state(reconstruction_loss_sens)\n",
    "        self.sens_kl_loss_tracker.update_state(kl_loss_sens)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss_ae\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss_ae\": self.kl_loss_tracker.result(),\n",
    "            \"reconstruction_loss_sens\": self.sens_reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss_sens\": self.sens_kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(429, 8)\n",
      "(429, 128, 256, 1)\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 128, 256, 1), dtype=tf.float64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# Prepare field data\n",
    "no_of_sensor = 8\n",
    "\n",
    "Re_list_train = [300, 400, 450, 500, 600, 650, 700, 800, 850, 900, 1000]\n",
    "Re_list_test = [350, 550, 750, 950]\n",
    "\n",
    "sensor_data_whole = []\n",
    "full_field_data_whole = []\n",
    "for Re in Re_list_train:\n",
    "    filename = \"D:/data/flow_field_recon/random_sensor_data/sensor_data_\" + str(no_of_sensor) + \"_\" + str(Re) + \".npy\"\n",
    "    sensor_data = np.load(filename)\n",
    "    sensor_data_whole.append(sensor_data)\n",
    "    filename_field = \"D:/data/flow_field_recon/full_field_data/full_field_data_\" + str(Re) + \".npy\"\n",
    "    full_field_data_whole.append(np.load(filename_field))\n",
    "\n",
    "sensor_data_whole_array = np.swapaxes(np.concatenate(sensor_data_whole,axis = -1), 0,1)\n",
    "full_field_data_whole_array = np.swapaxes(\n",
    "    np.expand_dims(\n",
    "        np.concatenate(full_field_data_whole, axis = -1), axis = 0),\n",
    "        0, -1)\n",
    "\n",
    "print(sensor_data_whole_array.shape)\n",
    "print(full_field_data_whole_array.shape)\n",
    "\n",
    "# Create tf.dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((sensor_data_whole_array,full_field_data_whole_array))\n",
    "dataset = dataset.shuffle(buffer_size = 2192) \n",
    "dataset = dataset.batch(8)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare sensor data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 3/54 [>.............................] - ETA: 3:48 - loss: 576577.4583 - reconstruction_loss_ae: 288485.6875 - kl_loss_ae: 5.7736e-05 - reconstruction_loss_sens: 288491.9062 - kl_loss_sens: 1.0598"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-46333dfd3921>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mflow_recon_net\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFLRNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mflow_recon_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.00001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.999\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mflow_recon_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\phong\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\phong\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1407\u001b[0m                 _r=1):\n\u001b[0;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\phong\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\phong\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\phong\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\phong\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2454\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2456\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\phong\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1861\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\phong\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    503\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\Users\\phong\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "flow_recon_net = FLRNet()\n",
    "flow_recon_net.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00001, beta_1 = 0.9, beta_2 = 0.999))\n",
    "flow_recon_net.fit(dataset, epochs = 100, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
